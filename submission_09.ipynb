{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submission_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKt61MtuqA8n1M9yT6jsAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inha-AI/DACON-semiconductor-competition/blob/feature%2FYoonSungLee/submission_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vVeUdyssBKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwHXDEigsNB0",
        "colab_type": "code",
        "outputId": "2dd53a11-87c9-4621-d2c1-e8acb54041a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BNXAU5rsPJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/train.csv')\n",
        "df_test = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdYXclfgsVr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 독립변수와 종속변수를 분리합니다.\n",
        "\n",
        "train_X = df_train.iloc[:,4:]\n",
        "train_Y = df_train.iloc[:,0:4]\n",
        "test_X = df_test.iloc[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s42dM3KndH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train set을 shuffle하여 다시 train set과 validation set으로 분리합니다.\n",
        "\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tT4w6XasaSQ",
        "colab_type": "text"
      },
      "source": [
        "# Model 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y25a2iOC4-2x",
        "colab_type": "text"
      },
      "source": [
        "* 6 layers\n",
        "* (239, 252, 265, 178, 91) units, he_normal, relu\n",
        "* BatchNormalization\n",
        "* Dropout(0.15)\n",
        "* Adam(0.008)\n",
        "* epochs 300\n",
        "* batch_size 1000\n",
        "<br><br>\n",
        "* layer층을 다시 복귀시킴\n",
        "* Dropout의 rate를 줄이고 다시 도입하여 overfitting 억제 시도\n",
        "* 대신 epochs를 대폭 늘려 가중치의 업데이트량을 증가시킴\n",
        "* sklearn의 train_test_split을 사용하여 train set과 validation set을 랜덤하게 추출\n",
        "* Model 1~8까지의 모델은 validation set을 train set의 끝에서 일정한 비율로 추출한 것이기 때문에, 그리고 너무 적은 비율로 추출했기 때문에 overfitting이 발생한 것처럼 보인 것이다. 하지만 이번 모델의 실험으로 알 수 있듯이 validation set을 랜덤하게 적절한 비율로 추출하면 실제 지금까지의 모델은 overfitting 문제는 아니라는 것을 알 수 있다. 따라서 Dropout의 필요성이 줄어들었고 모델을 정교하게 만드는 작업이 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PSSfoS5sfWK",
        "colab_type": "code",
        "outputId": "19579d78-ffff-4427-c21a-76162a38e189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 케라스를 통해 모델 생성을 시작합니다.\n",
        "\n",
        "model_09 = Sequential()\n",
        "model_09.add(Dense(units=239, input_dim=226, kernel_initializer='he_normal'))\n",
        "model_09.add(BatchNormalization())\n",
        "model_09.add(Activation('relu'))\n",
        "model_09.add(Dropout(0.15))\n",
        "model_09.add(Dense(units=252, kernel_initializer='he_normal'))\n",
        "model_09.add(BatchNormalization())\n",
        "model_09.add(Activation('relu'))\n",
        "model_09.add(Dropout(0.15))\n",
        "model_09.add(Dense(units=265, kernel_initializer='he_normal'))\n",
        "model_09.add(BatchNormalization())\n",
        "model_09.add(Activation('relu'))\n",
        "model_09.add(Dropout(0.15))\n",
        "model_09.add(Dense(units=178, kernel_initializer='he_normal'))\n",
        "model_09.add(BatchNormalization())\n",
        "model_09.add(Activation('relu'))\n",
        "model_09.add(Dropout(0.15))\n",
        "model_09.add(Dense(units=91, kernel_initializer='he_normal'))\n",
        "model_09.add(BatchNormalization())\n",
        "model_09.add(Activation('relu'))\n",
        "model_09.add(Dense(units=4, activation='linear'))\n",
        "\n",
        "adam = keras.optimizers.Adam(0.008)\n",
        "model_09.compile(loss='mae', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "hist = model_09.fit(train_X, train_Y, epochs=300, batch_size=1000,\n",
        "                    validation_data=(val_X, val_Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 455625 samples, validate on 151875 samples\n",
            "Epoch 1/300\n",
            "455625/455625 [==============================] - 12s 26us/step - loss: 65.5288 - acc: 0.3779 - val_loss: 53.9699 - val_acc: 0.4761\n",
            "Epoch 2/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 32.5035 - acc: 0.6578 - val_loss: 25.8295 - val_acc: 0.7298\n",
            "Epoch 3/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 25.8306 - acc: 0.7255 - val_loss: 19.6148 - val_acc: 0.7798\n",
            "Epoch 4/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 23.0458 - acc: 0.7533 - val_loss: 16.6097 - val_acc: 0.8138\n",
            "Epoch 5/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 21.4745 - acc: 0.7680 - val_loss: 14.5139 - val_acc: 0.8423\n",
            "Epoch 6/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 20.3485 - acc: 0.7801 - val_loss: 13.5515 - val_acc: 0.8540\n",
            "Epoch 7/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 19.5325 - acc: 0.7873 - val_loss: 12.8552 - val_acc: 0.8618\n",
            "Epoch 8/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 18.8865 - acc: 0.7947 - val_loss: 12.1641 - val_acc: 0.8640\n",
            "Epoch 9/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 18.3406 - acc: 0.7994 - val_loss: 11.2612 - val_acc: 0.8717\n",
            "Epoch 10/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 17.8502 - acc: 0.8047 - val_loss: 11.1338 - val_acc: 0.8768\n",
            "Epoch 11/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 17.5349 - acc: 0.8073 - val_loss: 10.2807 - val_acc: 0.8808\n",
            "Epoch 12/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 17.2309 - acc: 0.8115 - val_loss: 10.2845 - val_acc: 0.8813\n",
            "Epoch 13/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 16.9089 - acc: 0.8151 - val_loss: 9.8930 - val_acc: 0.8904\n",
            "Epoch 14/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 16.6718 - acc: 0.8160 - val_loss: 9.4679 - val_acc: 0.8974\n",
            "Epoch 15/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 16.4322 - acc: 0.8188 - val_loss: 9.7772 - val_acc: 0.8907\n",
            "Epoch 16/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 16.2721 - acc: 0.8201 - val_loss: 9.4199 - val_acc: 0.8939\n",
            "Epoch 17/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 16.0210 - acc: 0.8242 - val_loss: 9.2239 - val_acc: 0.8912\n",
            "Epoch 18/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.9363 - acc: 0.8244 - val_loss: 9.1392 - val_acc: 0.8940\n",
            "Epoch 19/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.7236 - acc: 0.8276 - val_loss: 8.7795 - val_acc: 0.9007\n",
            "Epoch 20/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.6223 - acc: 0.8278 - val_loss: 8.7095 - val_acc: 0.8982\n",
            "Epoch 21/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.4244 - acc: 0.8298 - val_loss: 8.6144 - val_acc: 0.9046\n",
            "Epoch 22/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.3500 - acc: 0.8306 - val_loss: 8.8729 - val_acc: 0.8975\n",
            "Epoch 23/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.2365 - acc: 0.8305 - val_loss: 8.4877 - val_acc: 0.9036\n",
            "Epoch 24/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 15.1547 - acc: 0.8323 - val_loss: 8.4611 - val_acc: 0.9038\n",
            "Epoch 25/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.9858 - acc: 0.8331 - val_loss: 8.2232 - val_acc: 0.9075\n",
            "Epoch 26/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.9674 - acc: 0.8343 - val_loss: 8.2490 - val_acc: 0.9067\n",
            "Epoch 27/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.8608 - acc: 0.8352 - val_loss: 8.2928 - val_acc: 0.9014\n",
            "Epoch 28/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.7189 - acc: 0.8370 - val_loss: 8.3520 - val_acc: 0.9002\n",
            "Epoch 29/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.7049 - acc: 0.8372 - val_loss: 8.0728 - val_acc: 0.9117\n",
            "Epoch 30/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.5973 - acc: 0.8373 - val_loss: 8.0194 - val_acc: 0.9106\n",
            "Epoch 31/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.5211 - acc: 0.8386 - val_loss: 8.0134 - val_acc: 0.9115\n",
            "Epoch 32/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.4282 - acc: 0.8404 - val_loss: 7.6466 - val_acc: 0.9133\n",
            "Epoch 33/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.4164 - acc: 0.8405 - val_loss: 7.8957 - val_acc: 0.9138\n",
            "Epoch 34/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.3453 - acc: 0.8407 - val_loss: 7.8056 - val_acc: 0.9069\n",
            "Epoch 35/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.2594 - acc: 0.8415 - val_loss: 7.7817 - val_acc: 0.9106\n",
            "Epoch 36/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.2513 - acc: 0.8420 - val_loss: 7.4525 - val_acc: 0.9126\n",
            "Epoch 37/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.1436 - acc: 0.8424 - val_loss: 7.3919 - val_acc: 0.9148\n",
            "Epoch 38/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.1251 - acc: 0.8431 - val_loss: 7.3411 - val_acc: 0.9147\n",
            "Epoch 39/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 14.0299 - acc: 0.8442 - val_loss: 7.3052 - val_acc: 0.9198\n",
            "Epoch 40/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 14.0017 - acc: 0.8434 - val_loss: 7.3754 - val_acc: 0.9071\n",
            "Epoch 41/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 13.9417 - acc: 0.8455 - val_loss: 7.2797 - val_acc: 0.9121\n",
            "Epoch 42/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 13.9259 - acc: 0.8453 - val_loss: 7.1527 - val_acc: 0.9188\n",
            "Epoch 43/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.8809 - acc: 0.8451 - val_loss: 7.2704 - val_acc: 0.9220\n",
            "Epoch 44/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.8080 - acc: 0.8455 - val_loss: 7.4006 - val_acc: 0.9194\n",
            "Epoch 45/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.7642 - acc: 0.8467 - val_loss: 7.0627 - val_acc: 0.9127\n",
            "Epoch 46/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.7321 - acc: 0.8480 - val_loss: 7.0397 - val_acc: 0.9255\n",
            "Epoch 47/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.6552 - acc: 0.8480 - val_loss: 7.1637 - val_acc: 0.9158\n",
            "Epoch 48/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 13.6345 - acc: 0.8481 - val_loss: 6.9926 - val_acc: 0.9208\n",
            "Epoch 49/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.6525 - acc: 0.8481 - val_loss: 6.7608 - val_acc: 0.9209\n",
            "Epoch 50/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.5483 - acc: 0.8488 - val_loss: 6.6561 - val_acc: 0.9177\n",
            "Epoch 51/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.5219 - acc: 0.8490 - val_loss: 7.0194 - val_acc: 0.9191\n",
            "Epoch 52/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.4927 - acc: 0.8502 - val_loss: 6.8783 - val_acc: 0.9244\n",
            "Epoch 53/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.4966 - acc: 0.8493 - val_loss: 6.7822 - val_acc: 0.9235\n",
            "Epoch 54/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.4265 - acc: 0.8505 - val_loss: 6.7408 - val_acc: 0.9229\n",
            "Epoch 55/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 13.3880 - acc: 0.8503 - val_loss: 7.2602 - val_acc: 0.9242\n",
            "Epoch 56/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.3224 - acc: 0.8515 - val_loss: 6.7906 - val_acc: 0.9279\n",
            "Epoch 57/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.3025 - acc: 0.8513 - val_loss: 6.7960 - val_acc: 0.9262\n",
            "Epoch 58/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.3777 - acc: 0.8497 - val_loss: 6.5554 - val_acc: 0.9204\n",
            "Epoch 59/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 13.2588 - acc: 0.8522 - val_loss: 6.7359 - val_acc: 0.9173\n",
            "Epoch 60/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.2143 - acc: 0.8522 - val_loss: 6.8054 - val_acc: 0.9293\n",
            "Epoch 61/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.2433 - acc: 0.8523 - val_loss: 6.7250 - val_acc: 0.9286\n",
            "Epoch 62/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.1287 - acc: 0.8533 - val_loss: 6.5399 - val_acc: 0.9247\n",
            "Epoch 63/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.1633 - acc: 0.8530 - val_loss: 6.5684 - val_acc: 0.9202\n",
            "Epoch 64/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.0784 - acc: 0.8542 - val_loss: 6.5297 - val_acc: 0.9304\n",
            "Epoch 65/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.0664 - acc: 0.8536 - val_loss: 6.8170 - val_acc: 0.9218\n",
            "Epoch 66/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 13.0778 - acc: 0.8546 - val_loss: 6.7821 - val_acc: 0.9273\n",
            "Epoch 67/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.0301 - acc: 0.8548 - val_loss: 6.4296 - val_acc: 0.9208\n",
            "Epoch 68/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 13.0471 - acc: 0.8542 - val_loss: 6.7242 - val_acc: 0.9240\n",
            "Epoch 69/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.9941 - acc: 0.8547 - val_loss: 6.2775 - val_acc: 0.9275\n",
            "Epoch 70/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.9813 - acc: 0.8553 - val_loss: 6.3539 - val_acc: 0.9283\n",
            "Epoch 71/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.9398 - acc: 0.8564 - val_loss: 6.2781 - val_acc: 0.9257\n",
            "Epoch 72/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.9374 - acc: 0.8552 - val_loss: 6.6055 - val_acc: 0.9248\n",
            "Epoch 73/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.8812 - acc: 0.8558 - val_loss: 6.5060 - val_acc: 0.9298\n",
            "Epoch 74/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.8899 - acc: 0.8556 - val_loss: 6.3874 - val_acc: 0.9232\n",
            "Epoch 75/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.8592 - acc: 0.8568 - val_loss: 6.3360 - val_acc: 0.9292\n",
            "Epoch 76/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.8383 - acc: 0.8565 - val_loss: 6.7094 - val_acc: 0.9320\n",
            "Epoch 77/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.8262 - acc: 0.8561 - val_loss: 6.4814 - val_acc: 0.9251\n",
            "Epoch 78/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.7674 - acc: 0.8572 - val_loss: 6.1537 - val_acc: 0.9279\n",
            "Epoch 79/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.7837 - acc: 0.8575 - val_loss: 6.3151 - val_acc: 0.9292\n",
            "Epoch 80/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.7587 - acc: 0.8574 - val_loss: 6.1730 - val_acc: 0.9293\n",
            "Epoch 81/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.6934 - acc: 0.8580 - val_loss: 6.8464 - val_acc: 0.9197\n",
            "Epoch 82/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.7369 - acc: 0.8581 - val_loss: 6.1522 - val_acc: 0.9282\n",
            "Epoch 83/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.6801 - acc: 0.8583 - val_loss: 6.3181 - val_acc: 0.9195\n",
            "Epoch 84/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.6577 - acc: 0.8585 - val_loss: 6.3733 - val_acc: 0.9226\n",
            "Epoch 85/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.6695 - acc: 0.8582 - val_loss: 6.2072 - val_acc: 0.9194\n",
            "Epoch 86/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.6420 - acc: 0.8589 - val_loss: 6.1557 - val_acc: 0.9236\n",
            "Epoch 87/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.6035 - acc: 0.8584 - val_loss: 6.4539 - val_acc: 0.9254\n",
            "Epoch 88/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.6203 - acc: 0.8590 - val_loss: 6.3384 - val_acc: 0.9284\n",
            "Epoch 89/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.5675 - acc: 0.8593 - val_loss: 6.3787 - val_acc: 0.9351\n",
            "Epoch 90/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.5872 - acc: 0.8595 - val_loss: 6.2443 - val_acc: 0.9276\n",
            "Epoch 91/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.5762 - acc: 0.8598 - val_loss: 6.2000 - val_acc: 0.9301\n",
            "Epoch 92/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.5407 - acc: 0.8595 - val_loss: 6.1678 - val_acc: 0.9264\n",
            "Epoch 93/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.5321 - acc: 0.8594 - val_loss: 6.0058 - val_acc: 0.9316\n",
            "Epoch 94/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4950 - acc: 0.8601 - val_loss: 6.0099 - val_acc: 0.9355\n",
            "Epoch 95/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4783 - acc: 0.8599 - val_loss: 6.2064 - val_acc: 0.9205\n",
            "Epoch 96/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4808 - acc: 0.8602 - val_loss: 6.2560 - val_acc: 0.9235\n",
            "Epoch 97/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4693 - acc: 0.8607 - val_loss: 6.1403 - val_acc: 0.9233\n",
            "Epoch 98/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4892 - acc: 0.8607 - val_loss: 5.9982 - val_acc: 0.9269\n",
            "Epoch 99/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4359 - acc: 0.8607 - val_loss: 5.8696 - val_acc: 0.9317\n",
            "Epoch 100/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.4422 - acc: 0.8613 - val_loss: 6.3856 - val_acc: 0.9348\n",
            "Epoch 101/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.4207 - acc: 0.8617 - val_loss: 6.1706 - val_acc: 0.9277\n",
            "Epoch 102/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3474 - acc: 0.8620 - val_loss: 6.0779 - val_acc: 0.9339\n",
            "Epoch 103/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3738 - acc: 0.8609 - val_loss: 6.1343 - val_acc: 0.9293\n",
            "Epoch 104/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3561 - acc: 0.8613 - val_loss: 5.9583 - val_acc: 0.9328\n",
            "Epoch 105/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3756 - acc: 0.8615 - val_loss: 5.9007 - val_acc: 0.9263\n",
            "Epoch 106/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.3127 - acc: 0.8620 - val_loss: 6.0750 - val_acc: 0.9367\n",
            "Epoch 107/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3488 - acc: 0.8616 - val_loss: 5.8401 - val_acc: 0.9325\n",
            "Epoch 108/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3212 - acc: 0.8621 - val_loss: 5.8939 - val_acc: 0.9332\n",
            "Epoch 109/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3419 - acc: 0.8618 - val_loss: 5.9346 - val_acc: 0.9315\n",
            "Epoch 110/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.3204 - acc: 0.8618 - val_loss: 5.9916 - val_acc: 0.9309\n",
            "Epoch 111/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.2876 - acc: 0.8624 - val_loss: 6.0393 - val_acc: 0.9219\n",
            "Epoch 112/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.2966 - acc: 0.8619 - val_loss: 5.9656 - val_acc: 0.9328\n",
            "Epoch 113/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.2177 - acc: 0.8638 - val_loss: 5.9330 - val_acc: 0.9298\n",
            "Epoch 114/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.2016 - acc: 0.8630 - val_loss: 5.9955 - val_acc: 0.9298\n",
            "Epoch 115/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.2441 - acc: 0.8624 - val_loss: 5.9079 - val_acc: 0.9298\n",
            "Epoch 116/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.2456 - acc: 0.8623 - val_loss: 5.8857 - val_acc: 0.9242\n",
            "Epoch 117/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.2243 - acc: 0.8632 - val_loss: 6.0395 - val_acc: 0.9311\n",
            "Epoch 118/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1777 - acc: 0.8637 - val_loss: 5.9443 - val_acc: 0.9271\n",
            "Epoch 119/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.2409 - acc: 0.8623 - val_loss: 6.0962 - val_acc: 0.9355\n",
            "Epoch 120/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.2302 - acc: 0.8623 - val_loss: 6.0219 - val_acc: 0.9203\n",
            "Epoch 121/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.1386 - acc: 0.8639 - val_loss: 5.9442 - val_acc: 0.9346\n",
            "Epoch 122/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1495 - acc: 0.8634 - val_loss: 6.2667 - val_acc: 0.9346\n",
            "Epoch 123/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1038 - acc: 0.8652 - val_loss: 5.8245 - val_acc: 0.9276\n",
            "Epoch 124/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1571 - acc: 0.8636 - val_loss: 5.6646 - val_acc: 0.9361\n",
            "Epoch 125/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1263 - acc: 0.8641 - val_loss: 5.9764 - val_acc: 0.9366\n",
            "Epoch 126/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.1005 - acc: 0.8649 - val_loss: 5.8052 - val_acc: 0.9323\n",
            "Epoch 127/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1161 - acc: 0.8637 - val_loss: 5.7874 - val_acc: 0.9310\n",
            "Epoch 128/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1039 - acc: 0.8641 - val_loss: 5.8497 - val_acc: 0.9256\n",
            "Epoch 129/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.0496 - acc: 0.8651 - val_loss: 5.6746 - val_acc: 0.9363\n",
            "Epoch 130/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.0652 - acc: 0.8650 - val_loss: 5.7093 - val_acc: 0.9294\n",
            "Epoch 131/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.0967 - acc: 0.8635 - val_loss: 6.0154 - val_acc: 0.9318\n",
            "Epoch 132/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.0425 - acc: 0.8654 - val_loss: 5.8222 - val_acc: 0.9324\n",
            "Epoch 133/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.0610 - acc: 0.8640 - val_loss: 5.6132 - val_acc: 0.9377\n",
            "Epoch 134/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 12.1069 - acc: 0.8646 - val_loss: 5.8786 - val_acc: 0.9358\n",
            "Epoch 135/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.0165 - acc: 0.8644 - val_loss: 5.6407 - val_acc: 0.9387\n",
            "Epoch 136/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.9713 - acc: 0.8658 - val_loss: 5.6427 - val_acc: 0.9295\n",
            "Epoch 137/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 12.0253 - acc: 0.8653 - val_loss: 5.7284 - val_acc: 0.9398\n",
            "Epoch 138/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9887 - acc: 0.8650 - val_loss: 5.5780 - val_acc: 0.9316\n",
            "Epoch 139/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9965 - acc: 0.8655 - val_loss: 5.7723 - val_acc: 0.9378\n",
            "Epoch 140/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9616 - acc: 0.8655 - val_loss: 5.8261 - val_acc: 0.9353\n",
            "Epoch 141/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.9756 - acc: 0.8651 - val_loss: 5.5815 - val_acc: 0.9313\n",
            "Epoch 142/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9406 - acc: 0.8665 - val_loss: 5.8240 - val_acc: 0.9384\n",
            "Epoch 143/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9809 - acc: 0.8657 - val_loss: 5.6063 - val_acc: 0.9333\n",
            "Epoch 144/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9467 - acc: 0.8653 - val_loss: 5.7348 - val_acc: 0.9304\n",
            "Epoch 145/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9199 - acc: 0.8661 - val_loss: 5.8236 - val_acc: 0.9386\n",
            "Epoch 146/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9099 - acc: 0.8658 - val_loss: 5.6642 - val_acc: 0.9325\n",
            "Epoch 147/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9313 - acc: 0.8656 - val_loss: 5.5242 - val_acc: 0.9357\n",
            "Epoch 148/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.8944 - acc: 0.8662 - val_loss: 5.6803 - val_acc: 0.9255\n",
            "Epoch 149/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8501 - acc: 0.8668 - val_loss: 5.6790 - val_acc: 0.9385\n",
            "Epoch 150/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9349 - acc: 0.8659 - val_loss: 5.6413 - val_acc: 0.9355\n",
            "Epoch 151/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.9428 - acc: 0.8658 - val_loss: 5.6802 - val_acc: 0.9296\n",
            "Epoch 152/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8349 - acc: 0.8671 - val_loss: 5.5201 - val_acc: 0.9357\n",
            "Epoch 153/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.8586 - acc: 0.8668 - val_loss: 5.5824 - val_acc: 0.9377\n",
            "Epoch 154/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.8559 - acc: 0.8666 - val_loss: 5.4419 - val_acc: 0.9326\n",
            "Epoch 155/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.8887 - acc: 0.8667 - val_loss: 5.5585 - val_acc: 0.9372\n",
            "Epoch 156/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8076 - acc: 0.8677 - val_loss: 5.9015 - val_acc: 0.9373\n",
            "Epoch 157/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8503 - acc: 0.8672 - val_loss: 5.6953 - val_acc: 0.9378\n",
            "Epoch 158/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8085 - acc: 0.8672 - val_loss: 5.6226 - val_acc: 0.9314\n",
            "Epoch 159/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8146 - acc: 0.8673 - val_loss: 5.7686 - val_acc: 0.9390\n",
            "Epoch 160/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.8688 - acc: 0.8661 - val_loss: 5.4565 - val_acc: 0.9370\n",
            "Epoch 161/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7870 - acc: 0.8679 - val_loss: 5.4758 - val_acc: 0.9383\n",
            "Epoch 162/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.7666 - acc: 0.8679 - val_loss: 5.5788 - val_acc: 0.9286\n",
            "Epoch 163/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7734 - acc: 0.8680 - val_loss: 5.4973 - val_acc: 0.9342\n",
            "Epoch 164/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.7381 - acc: 0.8680 - val_loss: 5.6537 - val_acc: 0.9373\n",
            "Epoch 165/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.7286 - acc: 0.8679 - val_loss: 5.5696 - val_acc: 0.9308\n",
            "Epoch 166/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.8106 - acc: 0.8671 - val_loss: 5.5708 - val_acc: 0.9378\n",
            "Epoch 167/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.7595 - acc: 0.8682 - val_loss: 5.5663 - val_acc: 0.9301\n",
            "Epoch 168/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7075 - acc: 0.8683 - val_loss: 5.4287 - val_acc: 0.9339\n",
            "Epoch 169/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.6948 - acc: 0.8690 - val_loss: 5.5365 - val_acc: 0.9286\n",
            "Epoch 170/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7217 - acc: 0.8685 - val_loss: 5.7995 - val_acc: 0.9399\n",
            "Epoch 171/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6683 - acc: 0.8690 - val_loss: 5.6585 - val_acc: 0.9351\n",
            "Epoch 172/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.7542 - acc: 0.8677 - val_loss: 5.6910 - val_acc: 0.9340\n",
            "Epoch 173/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7533 - acc: 0.8681 - val_loss: 5.4937 - val_acc: 0.9392\n",
            "Epoch 174/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.6980 - acc: 0.8687 - val_loss: 5.4097 - val_acc: 0.9372\n",
            "Epoch 175/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7284 - acc: 0.8680 - val_loss: 5.7078 - val_acc: 0.9242\n",
            "Epoch 176/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7474 - acc: 0.8676 - val_loss: 5.4655 - val_acc: 0.9396\n",
            "Epoch 177/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.7150 - acc: 0.8691 - val_loss: 5.4798 - val_acc: 0.9371\n",
            "Epoch 178/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7069 - acc: 0.8686 - val_loss: 5.4766 - val_acc: 0.9348\n",
            "Epoch 179/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6980 - acc: 0.8685 - val_loss: 5.4394 - val_acc: 0.9347\n",
            "Epoch 180/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.7499 - acc: 0.8680 - val_loss: 5.3746 - val_acc: 0.9377\n",
            "Epoch 181/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6486 - acc: 0.8695 - val_loss: 5.5047 - val_acc: 0.9375\n",
            "Epoch 182/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6791 - acc: 0.8689 - val_loss: 5.6173 - val_acc: 0.9325\n",
            "Epoch 183/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6434 - acc: 0.8695 - val_loss: 5.5305 - val_acc: 0.9289\n",
            "Epoch 184/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6404 - acc: 0.8697 - val_loss: 5.4789 - val_acc: 0.9388\n",
            "Epoch 185/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6477 - acc: 0.8691 - val_loss: 5.4969 - val_acc: 0.9367\n",
            "Epoch 186/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6408 - acc: 0.8692 - val_loss: 5.5105 - val_acc: 0.9418\n",
            "Epoch 187/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6718 - acc: 0.8677 - val_loss: 5.3683 - val_acc: 0.9354\n",
            "Epoch 188/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.6329 - acc: 0.8699 - val_loss: 5.3352 - val_acc: 0.9324\n",
            "Epoch 189/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.6077 - acc: 0.8704 - val_loss: 5.5134 - val_acc: 0.9269\n",
            "Epoch 190/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.6315 - acc: 0.8689 - val_loss: 5.3009 - val_acc: 0.9376\n",
            "Epoch 191/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5829 - acc: 0.8701 - val_loss: 5.5305 - val_acc: 0.9405\n",
            "Epoch 192/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5926 - acc: 0.8692 - val_loss: 5.3565 - val_acc: 0.9398\n",
            "Epoch 193/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6875 - acc: 0.8688 - val_loss: 5.3290 - val_acc: 0.9381\n",
            "Epoch 194/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6298 - acc: 0.8693 - val_loss: 5.3677 - val_acc: 0.9405\n",
            "Epoch 195/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5861 - acc: 0.8698 - val_loss: 5.4312 - val_acc: 0.9378\n",
            "Epoch 196/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5860 - acc: 0.8699 - val_loss: 5.4344 - val_acc: 0.9411\n",
            "Epoch 197/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.6310 - acc: 0.8687 - val_loss: 5.3691 - val_acc: 0.9354\n",
            "Epoch 198/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5765 - acc: 0.8700 - val_loss: 5.2868 - val_acc: 0.9364\n",
            "Epoch 199/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5582 - acc: 0.8701 - val_loss: 5.3273 - val_acc: 0.9307\n",
            "Epoch 200/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5647 - acc: 0.8697 - val_loss: 5.4790 - val_acc: 0.9257\n",
            "Epoch 201/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5912 - acc: 0.8697 - val_loss: 5.4984 - val_acc: 0.9350\n",
            "Epoch 202/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5675 - acc: 0.8697 - val_loss: 5.4322 - val_acc: 0.9333\n",
            "Epoch 203/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4998 - acc: 0.8704 - val_loss: 5.4724 - val_acc: 0.9371\n",
            "Epoch 204/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5218 - acc: 0.8708 - val_loss: 5.3841 - val_acc: 0.9422\n",
            "Epoch 205/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.5133 - acc: 0.8703 - val_loss: 5.4152 - val_acc: 0.9419\n",
            "Epoch 206/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5618 - acc: 0.8704 - val_loss: 5.3465 - val_acc: 0.9369\n",
            "Epoch 207/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5083 - acc: 0.8703 - val_loss: 5.3268 - val_acc: 0.9396\n",
            "Epoch 208/300\n",
            "455625/455625 [==============================] - 8s 17us/step - loss: 11.5138 - acc: 0.8712 - val_loss: 5.3070 - val_acc: 0.9374\n",
            "Epoch 209/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5384 - acc: 0.8704 - val_loss: 5.5372 - val_acc: 0.9337\n",
            "Epoch 210/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.5285 - acc: 0.8702 - val_loss: 5.3946 - val_acc: 0.9306\n",
            "Epoch 211/300\n",
            "455625/455625 [==============================] - 8s 19us/step - loss: 11.4959 - acc: 0.8711 - val_loss: 5.3795 - val_acc: 0.9407\n",
            "Epoch 212/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4752 - acc: 0.8707 - val_loss: 5.3779 - val_acc: 0.9302\n",
            "Epoch 213/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4703 - acc: 0.8701 - val_loss: 5.3313 - val_acc: 0.9354\n",
            "Epoch 214/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4621 - acc: 0.8703 - val_loss: 5.3147 - val_acc: 0.9390\n",
            "Epoch 215/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.5065 - acc: 0.8703 - val_loss: 5.3145 - val_acc: 0.9366\n",
            "Epoch 216/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4919 - acc: 0.8708 - val_loss: 5.4791 - val_acc: 0.9328\n",
            "Epoch 217/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4822 - acc: 0.8711 - val_loss: 5.2285 - val_acc: 0.9342\n",
            "Epoch 218/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4622 - acc: 0.8709 - val_loss: 5.2054 - val_acc: 0.9415\n",
            "Epoch 219/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4568 - acc: 0.8707 - val_loss: 5.3915 - val_acc: 0.9332\n",
            "Epoch 220/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4592 - acc: 0.8705 - val_loss: 5.4025 - val_acc: 0.9388\n",
            "Epoch 221/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4871 - acc: 0.8709 - val_loss: 5.4925 - val_acc: 0.9385\n",
            "Epoch 222/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4459 - acc: 0.8713 - val_loss: 5.4907 - val_acc: 0.9352\n",
            "Epoch 223/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.3843 - acc: 0.8725 - val_loss: 5.3115 - val_acc: 0.9390\n",
            "Epoch 224/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4583 - acc: 0.8706 - val_loss: 5.2334 - val_acc: 0.9373\n",
            "Epoch 225/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4366 - acc: 0.8720 - val_loss: 5.3236 - val_acc: 0.9435\n",
            "Epoch 226/300\n",
            "455625/455625 [==============================] - 9s 20us/step - loss: 11.4398 - acc: 0.8713 - val_loss: 5.2304 - val_acc: 0.9343\n",
            "Epoch 227/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.3966 - acc: 0.8717 - val_loss: 5.4607 - val_acc: 0.9393\n",
            "Epoch 228/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.3940 - acc: 0.8719 - val_loss: 5.3369 - val_acc: 0.9302\n",
            "Epoch 229/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4219 - acc: 0.8713 - val_loss: 5.2064 - val_acc: 0.9348\n",
            "Epoch 230/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4202 - acc: 0.8718 - val_loss: 5.3013 - val_acc: 0.9386\n",
            "Epoch 231/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4119 - acc: 0.8712 - val_loss: 5.3857 - val_acc: 0.9384\n",
            "Epoch 232/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4012 - acc: 0.8715 - val_loss: 5.2462 - val_acc: 0.9388\n",
            "Epoch 233/300\n",
            "455625/455625 [==============================] - 8s 19us/step - loss: 11.3878 - acc: 0.8716 - val_loss: 5.4424 - val_acc: 0.9286\n",
            "Epoch 234/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4084 - acc: 0.8720 - val_loss: 5.1763 - val_acc: 0.9385\n",
            "Epoch 235/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.4159 - acc: 0.8720 - val_loss: 5.1329 - val_acc: 0.9403\n",
            "Epoch 236/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3491 - acc: 0.8722 - val_loss: 5.2704 - val_acc: 0.9332\n",
            "Epoch 237/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3948 - acc: 0.8713 - val_loss: 5.4630 - val_acc: 0.9415\n",
            "Epoch 238/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3638 - acc: 0.8715 - val_loss: 5.5731 - val_acc: 0.9365\n",
            "Epoch 239/300\n",
            "455625/455625 [==============================] - 8s 19us/step - loss: 11.4046 - acc: 0.8715 - val_loss: 5.4064 - val_acc: 0.9360\n",
            "Epoch 240/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3605 - acc: 0.8718 - val_loss: 5.5447 - val_acc: 0.9330\n",
            "Epoch 241/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3975 - acc: 0.8715 - val_loss: 5.2521 - val_acc: 0.9430\n",
            "Epoch 242/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.4078 - acc: 0.8716 - val_loss: 5.3914 - val_acc: 0.9382\n",
            "Epoch 243/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3467 - acc: 0.8726 - val_loss: 5.2814 - val_acc: 0.9427\n",
            "Epoch 244/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3773 - acc: 0.8723 - val_loss: 5.3710 - val_acc: 0.9400\n",
            "Epoch 245/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3817 - acc: 0.8718 - val_loss: 5.2406 - val_acc: 0.9386\n",
            "Epoch 246/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3368 - acc: 0.8726 - val_loss: 5.4494 - val_acc: 0.9377\n",
            "Epoch 247/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3597 - acc: 0.8724 - val_loss: 5.1782 - val_acc: 0.9361\n",
            "Epoch 248/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2930 - acc: 0.8729 - val_loss: 5.3660 - val_acc: 0.9388\n",
            "Epoch 249/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3190 - acc: 0.8726 - val_loss: 5.2658 - val_acc: 0.9439\n",
            "Epoch 250/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3177 - acc: 0.8720 - val_loss: 5.1442 - val_acc: 0.9321\n",
            "Epoch 251/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3095 - acc: 0.8725 - val_loss: 5.1799 - val_acc: 0.9333\n",
            "Epoch 252/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3201 - acc: 0.8730 - val_loss: 5.2543 - val_acc: 0.9348\n",
            "Epoch 253/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2985 - acc: 0.8731 - val_loss: 5.2023 - val_acc: 0.9423\n",
            "Epoch 254/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2904 - acc: 0.8729 - val_loss: 5.5201 - val_acc: 0.9349\n",
            "Epoch 255/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3181 - acc: 0.8723 - val_loss: 5.1532 - val_acc: 0.9428\n",
            "Epoch 256/300\n",
            "455625/455625 [==============================] - 8s 19us/step - loss: 11.3206 - acc: 0.8725 - val_loss: 5.3998 - val_acc: 0.9361\n",
            "Epoch 257/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.3284 - acc: 0.8729 - val_loss: 5.3319 - val_acc: 0.9346\n",
            "Epoch 258/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2827 - acc: 0.8732 - val_loss: 5.1763 - val_acc: 0.9385\n",
            "Epoch 259/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2831 - acc: 0.8731 - val_loss: 5.1105 - val_acc: 0.9429\n",
            "Epoch 260/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2607 - acc: 0.8730 - val_loss: 5.4299 - val_acc: 0.9391\n",
            "Epoch 261/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.3161 - acc: 0.8723 - val_loss: 5.3166 - val_acc: 0.9319\n",
            "Epoch 262/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2956 - acc: 0.8731 - val_loss: 5.3053 - val_acc: 0.9433\n",
            "Epoch 263/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2911 - acc: 0.8725 - val_loss: 5.2341 - val_acc: 0.9440\n",
            "Epoch 264/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2595 - acc: 0.8740 - val_loss: 5.1330 - val_acc: 0.9418\n",
            "Epoch 265/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2483 - acc: 0.8733 - val_loss: 5.1946 - val_acc: 0.9391\n",
            "Epoch 266/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.2934 - acc: 0.8723 - val_loss: 5.1566 - val_acc: 0.9401\n",
            "Epoch 267/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.2281 - acc: 0.8733 - val_loss: 5.2601 - val_acc: 0.9398\n",
            "Epoch 268/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.2886 - acc: 0.8732 - val_loss: 5.3095 - val_acc: 0.9303\n",
            "Epoch 269/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.1768 - acc: 0.8743 - val_loss: 5.1013 - val_acc: 0.9444\n",
            "Epoch 270/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.2506 - acc: 0.8726 - val_loss: 5.1233 - val_acc: 0.9413\n",
            "Epoch 271/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2496 - acc: 0.8736 - val_loss: 5.1260 - val_acc: 0.9361\n",
            "Epoch 272/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2453 - acc: 0.8735 - val_loss: 5.1790 - val_acc: 0.9399\n",
            "Epoch 273/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2826 - acc: 0.8723 - val_loss: 5.1211 - val_acc: 0.9313\n",
            "Epoch 274/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.2380 - acc: 0.8732 - val_loss: 5.1458 - val_acc: 0.9402\n",
            "Epoch 275/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.2640 - acc: 0.8726 - val_loss: 5.5817 - val_acc: 0.9301\n",
            "Epoch 276/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2219 - acc: 0.8740 - val_loss: 5.5901 - val_acc: 0.9443\n",
            "Epoch 277/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2169 - acc: 0.8729 - val_loss: 5.1291 - val_acc: 0.9346\n",
            "Epoch 278/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2524 - acc: 0.8735 - val_loss: 5.4108 - val_acc: 0.9310\n",
            "Epoch 279/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1953 - acc: 0.8745 - val_loss: 5.1177 - val_acc: 0.9399\n",
            "Epoch 280/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1983 - acc: 0.8738 - val_loss: 5.1521 - val_acc: 0.9407\n",
            "Epoch 281/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2819 - acc: 0.8734 - val_loss: 5.1569 - val_acc: 0.9415\n",
            "Epoch 282/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2384 - acc: 0.8730 - val_loss: 4.9679 - val_acc: 0.9379\n",
            "Epoch 283/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1812 - acc: 0.8740 - val_loss: 5.0138 - val_acc: 0.9439\n",
            "Epoch 284/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1938 - acc: 0.8743 - val_loss: 5.0792 - val_acc: 0.9405\n",
            "Epoch 285/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2205 - acc: 0.8738 - val_loss: 5.2166 - val_acc: 0.9379\n",
            "Epoch 286/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1828 - acc: 0.8745 - val_loss: 5.3548 - val_acc: 0.9382\n",
            "Epoch 287/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1966 - acc: 0.8737 - val_loss: 5.3104 - val_acc: 0.9285\n",
            "Epoch 288/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1901 - acc: 0.8737 - val_loss: 5.4440 - val_acc: 0.9356\n",
            "Epoch 289/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1960 - acc: 0.8745 - val_loss: 5.1162 - val_acc: 0.9417\n",
            "Epoch 290/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2044 - acc: 0.8734 - val_loss: 5.2208 - val_acc: 0.9349\n",
            "Epoch 291/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1676 - acc: 0.8745 - val_loss: 4.9915 - val_acc: 0.9364\n",
            "Epoch 292/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1483 - acc: 0.8749 - val_loss: 5.2295 - val_acc: 0.9387\n",
            "Epoch 293/300\n",
            "455625/455625 [==============================] - 8s 19us/step - loss: 11.1844 - acc: 0.8733 - val_loss: 5.0667 - val_acc: 0.9438\n",
            "Epoch 294/300\n",
            "455625/455625 [==============================] - 9s 19us/step - loss: 11.1337 - acc: 0.8746 - val_loss: 5.1510 - val_acc: 0.9381\n",
            "Epoch 295/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1505 - acc: 0.8745 - val_loss: 5.2762 - val_acc: 0.9417\n",
            "Epoch 296/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.2023 - acc: 0.8747 - val_loss: 5.1484 - val_acc: 0.9331\n",
            "Epoch 297/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1746 - acc: 0.8735 - val_loss: 4.9591 - val_acc: 0.9399\n",
            "Epoch 298/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1430 - acc: 0.8750 - val_loss: 4.9957 - val_acc: 0.9402\n",
            "Epoch 299/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1237 - acc: 0.8746 - val_loss: 5.2788 - val_acc: 0.9339\n",
            "Epoch 300/300\n",
            "455625/455625 [==============================] - 8s 18us/step - loss: 11.1526 - acc: 0.8738 - val_loss: 5.2111 - val_acc: 0.9339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzHV2L2swuGQ",
        "colab_type": "code",
        "outputId": "0699a692-8550-4b27-bbaf-dd4e603398f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 모델 아키텍처\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model_09, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"2287pt\" viewBox=\"0.00 0.00 431.00 1715.00\" width=\"575pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 1711)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1711 427,-1711 427,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140002907594936 -->\n<g class=\"node\" id=\"node1\">\n<title>140002907594936</title>\n<polygon fill=\"none\" points=\"49,-1660.5 49,-1706.5 374,-1706.5 374,-1660.5 49,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1679.8\">dense_49_input: InputLayer</text>\n<polyline fill=\"none\" points=\"229,-1660.5 229,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"229,-1683.5 287,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"287,-1660.5 287,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330.5\" y=\"-1691.3\">(None, 226)</text>\n<polyline fill=\"none\" points=\"287,-1683.5 374,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330.5\" y=\"-1668.3\">(None, 226)</text>\n</g>\n<!-- 140002907639536 -->\n<g class=\"node\" id=\"node2\">\n<title>140002907639536</title>\n<polygon fill=\"none\" points=\"82,-1577.5 82,-1623.5 341,-1623.5 341,-1577.5 82,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1596.8\">dense_49: Dense</text>\n<polyline fill=\"none\" points=\"196,-1577.5 196,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-1600.5 254,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-1577.5 254,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-1608.3\">(None, 226)</text>\n<polyline fill=\"none\" points=\"254,-1600.5 341,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-1585.3\">(None, 239)</text>\n</g>\n<!-- 140002907594936&#45;&gt;140002907639536 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140002907594936-&gt;140002907639536</title>\n<path d=\"M211.5,-1660.3799C211.5,-1652.1745 211.5,-1642.7679 211.5,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1633.784 211.5,-1623.784 208.0001,-1633.784 215.0001,-1633.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907639648 -->\n<g class=\"node\" id=\"node3\">\n<title>140002907639648</title>\n<polygon fill=\"none\" points=\"0,-1494.5 0,-1540.5 423,-1540.5 423,-1494.5 0,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1513.8\">batch_normalization_41: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-1494.5 278,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-1517.5 336,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-1494.5 336,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-1525.3\">(None, 239)</text>\n<polyline fill=\"none\" points=\"336,-1517.5 423,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-1502.3\">(None, 239)</text>\n</g>\n<!-- 140002907639536&#45;&gt;140002907639648 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140002907639536-&gt;140002907639648</title>\n<path d=\"M211.5,-1577.3799C211.5,-1569.1745 211.5,-1559.7679 211.5,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1550.784 211.5,-1540.784 208.0001,-1550.784 215.0001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907598632 -->\n<g class=\"node\" id=\"node4\">\n<title>140002907598632</title>\n<polygon fill=\"none\" points=\"58.5,-1411.5 58.5,-1457.5 364.5,-1457.5 364.5,-1411.5 58.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1430.8\">activation_41: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-1411.5 219.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-1434.5 277.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-1411.5 277.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1442.3\">(None, 239)</text>\n<polyline fill=\"none\" points=\"277.5,-1434.5 364.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1419.3\">(None, 239)</text>\n</g>\n<!-- 140002907639648&#45;&gt;140002907598632 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140002907639648-&gt;140002907598632</title>\n<path d=\"M211.5,-1494.3799C211.5,-1486.1745 211.5,-1476.7679 211.5,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1467.784 211.5,-1457.784 208.0001,-1467.784 215.0001,-1467.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907574792 -->\n<g class=\"node\" id=\"node5\">\n<title>140002907574792</title>\n<polygon fill=\"none\" points=\"68.5,-1328.5 68.5,-1374.5 354.5,-1374.5 354.5,-1328.5 68.5,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1347.8\">dropout_29: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-1328.5 209.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-1351.5 267.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-1328.5 267.5,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-1359.3\">(None, 239)</text>\n<polyline fill=\"none\" points=\"267.5,-1351.5 354.5,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-1336.3\">(None, 239)</text>\n</g>\n<!-- 140002907598632&#45;&gt;140002907574792 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140002907598632-&gt;140002907574792</title>\n<path d=\"M211.5,-1411.3799C211.5,-1403.1745 211.5,-1393.7679 211.5,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1384.784 211.5,-1374.784 208.0001,-1384.784 215.0001,-1384.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907757592 -->\n<g class=\"node\" id=\"node6\">\n<title>140002907757592</title>\n<polygon fill=\"none\" points=\"82,-1245.5 82,-1291.5 341,-1291.5 341,-1245.5 82,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1264.8\">dense_50: Dense</text>\n<polyline fill=\"none\" points=\"196,-1245.5 196,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-1268.5 254,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-1245.5 254,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-1276.3\">(None, 239)</text>\n<polyline fill=\"none\" points=\"254,-1268.5 341,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-1253.3\">(None, 252)</text>\n</g>\n<!-- 140002907574792&#45;&gt;140002907757592 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140002907574792-&gt;140002907757592</title>\n<path d=\"M211.5,-1328.3799C211.5,-1320.1745 211.5,-1310.7679 211.5,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1301.784 211.5,-1291.784 208.0001,-1301.784 215.0001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907776728 -->\n<g class=\"node\" id=\"node7\">\n<title>140002907776728</title>\n<polygon fill=\"none\" points=\"0,-1162.5 0,-1208.5 423,-1208.5 423,-1162.5 0,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1181.8\">batch_normalization_42: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-1162.5 278,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-1185.5 336,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-1162.5 336,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-1193.3\">(None, 252)</text>\n<polyline fill=\"none\" points=\"336,-1185.5 423,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-1170.3\">(None, 252)</text>\n</g>\n<!-- 140002907757592&#45;&gt;140002907776728 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140002907757592-&gt;140002907776728</title>\n<path d=\"M211.5,-1245.3799C211.5,-1237.1745 211.5,-1227.7679 211.5,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1218.784 211.5,-1208.784 208.0001,-1218.784 215.0001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907446744 -->\n<g class=\"node\" id=\"node8\">\n<title>140002907446744</title>\n<polygon fill=\"none\" points=\"58.5,-1079.5 58.5,-1125.5 364.5,-1125.5 364.5,-1079.5 58.5,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1098.8\">activation_42: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-1079.5 219.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-1102.5 277.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-1079.5 277.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1110.3\">(None, 252)</text>\n<polyline fill=\"none\" points=\"277.5,-1102.5 364.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-1087.3\">(None, 252)</text>\n</g>\n<!-- 140002907776728&#45;&gt;140002907446744 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140002907776728-&gt;140002907446744</title>\n<path d=\"M211.5,-1162.3799C211.5,-1154.1745 211.5,-1144.7679 211.5,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1135.784 211.5,-1125.784 208.0001,-1135.784 215.0001,-1135.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907509928 -->\n<g class=\"node\" id=\"node9\">\n<title>140002907509928</title>\n<polygon fill=\"none\" points=\"68.5,-996.5 68.5,-1042.5 354.5,-1042.5 354.5,-996.5 68.5,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-1015.8\">dropout_30: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-996.5 209.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-1019.5 267.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-996.5 267.5,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-1027.3\">(None, 252)</text>\n<polyline fill=\"none\" points=\"267.5,-1019.5 354.5,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-1004.3\">(None, 252)</text>\n</g>\n<!-- 140002907446744&#45;&gt;140002907509928 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140002907446744-&gt;140002907509928</title>\n<path d=\"M211.5,-1079.3799C211.5,-1071.1745 211.5,-1061.7679 211.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-1052.784 211.5,-1042.784 208.0001,-1052.784 215.0001,-1052.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907037536 -->\n<g class=\"node\" id=\"node10\">\n<title>140002907037536</title>\n<polygon fill=\"none\" points=\"82,-913.5 82,-959.5 341,-959.5 341,-913.5 82,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-932.8\">dense_51: Dense</text>\n<polyline fill=\"none\" points=\"196,-913.5 196,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-936.5 254,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-913.5 254,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-944.3\">(None, 252)</text>\n<polyline fill=\"none\" points=\"254,-936.5 341,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-921.3\">(None, 265)</text>\n</g>\n<!-- 140002907509928&#45;&gt;140002907037536 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140002907509928-&gt;140002907037536</title>\n<path d=\"M211.5,-996.3799C211.5,-988.1745 211.5,-978.7679 211.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-969.784 211.5,-959.784 208.0001,-969.784 215.0001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002907091968 -->\n<g class=\"node\" id=\"node11\">\n<title>140002907091968</title>\n<polygon fill=\"none\" points=\"0,-830.5 0,-876.5 423,-876.5 423,-830.5 0,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-849.8\">batch_normalization_43: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-830.5 278,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-853.5 336,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-830.5 336,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-861.3\">(None, 265)</text>\n<polyline fill=\"none\" points=\"336,-853.5 423,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-838.3\">(None, 265)</text>\n</g>\n<!-- 140002907037536&#45;&gt;140002907091968 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140002907037536-&gt;140002907091968</title>\n<path d=\"M211.5,-913.3799C211.5,-905.1745 211.5,-895.7679 211.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-886.784 211.5,-876.784 208.0001,-886.784 215.0001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906788920 -->\n<g class=\"node\" id=\"node12\">\n<title>140002906788920</title>\n<polygon fill=\"none\" points=\"58.5,-747.5 58.5,-793.5 364.5,-793.5 364.5,-747.5 58.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-766.8\">activation_43: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-747.5 219.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-770.5 277.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-747.5 277.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-778.3\">(None, 265)</text>\n<polyline fill=\"none\" points=\"277.5,-770.5 364.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-755.3\">(None, 265)</text>\n</g>\n<!-- 140002907091968&#45;&gt;140002906788920 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140002907091968-&gt;140002906788920</title>\n<path d=\"M211.5,-830.3799C211.5,-822.1745 211.5,-812.7679 211.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-803.784 211.5,-793.784 208.0001,-803.784 215.0001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906828696 -->\n<g class=\"node\" id=\"node13\">\n<title>140002906828696</title>\n<polygon fill=\"none\" points=\"68.5,-664.5 68.5,-710.5 354.5,-710.5 354.5,-664.5 68.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-683.8\">dropout_31: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-664.5 209.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-687.5 267.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-664.5 267.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-695.3\">(None, 265)</text>\n<polyline fill=\"none\" points=\"267.5,-687.5 354.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-672.3\">(None, 265)</text>\n</g>\n<!-- 140002906788920&#45;&gt;140002906828696 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140002906788920-&gt;140002906828696</title>\n<path d=\"M211.5,-747.3799C211.5,-739.1745 211.5,-729.7679 211.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-720.784 211.5,-710.784 208.0001,-720.784 215.0001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906489520 -->\n<g class=\"node\" id=\"node14\">\n<title>140002906489520</title>\n<polygon fill=\"none\" points=\"82,-581.5 82,-627.5 341,-627.5 341,-581.5 82,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-600.8\">dense_52: Dense</text>\n<polyline fill=\"none\" points=\"196,-581.5 196,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-604.5 254,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-581.5 254,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-612.3\">(None, 265)</text>\n<polyline fill=\"none\" points=\"254,-604.5 341,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-589.3\">(None, 178)</text>\n</g>\n<!-- 140002906828696&#45;&gt;140002906489520 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140002906828696-&gt;140002906489520</title>\n<path d=\"M211.5,-664.3799C211.5,-656.1745 211.5,-646.7679 211.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-637.784 211.5,-627.784 208.0001,-637.784 215.0001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906952648 -->\n<g class=\"node\" id=\"node15\">\n<title>140002906952648</title>\n<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 423,-544.5 423,-498.5 0,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-517.8\">batch_normalization_44: BatchNormalization</text>\n<polyline fill=\"none\" points=\"278,-498.5 278,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"278,-521.5 336,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"307\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"336,-498.5 336,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-529.3\">(None, 178)</text>\n<polyline fill=\"none\" points=\"336,-521.5 423,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-506.3\">(None, 178)</text>\n</g>\n<!-- 140002906489520&#45;&gt;140002906952648 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140002906489520-&gt;140002906952648</title>\n<path d=\"M211.5,-581.3799C211.5,-573.1745 211.5,-563.7679 211.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-554.784 211.5,-544.784 208.0001,-554.784 215.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906622776 -->\n<g class=\"node\" id=\"node16\">\n<title>140002906622776</title>\n<polygon fill=\"none\" points=\"58.5,-415.5 58.5,-461.5 364.5,-461.5 364.5,-415.5 58.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-434.8\">activation_44: Activation</text>\n<polyline fill=\"none\" points=\"219.5,-415.5 219.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"219.5,-438.5 277.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"277.5,-415.5 277.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-446.3\">(None, 178)</text>\n<polyline fill=\"none\" points=\"277.5,-438.5 364.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-423.3\">(None, 178)</text>\n</g>\n<!-- 140002906952648&#45;&gt;140002906622776 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140002906952648-&gt;140002906622776</title>\n<path d=\"M211.5,-498.3799C211.5,-490.1745 211.5,-480.7679 211.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-471.784 211.5,-461.784 208.0001,-471.784 215.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906682144 -->\n<g class=\"node\" id=\"node17\">\n<title>140002906682144</title>\n<polygon fill=\"none\" points=\"68.5,-332.5 68.5,-378.5 354.5,-378.5 354.5,-332.5 68.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-351.8\">dropout_32: Dropout</text>\n<polyline fill=\"none\" points=\"209.5,-332.5 209.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"209.5,-355.5 267.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"267.5,-332.5 267.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-363.3\">(None, 178)</text>\n<polyline fill=\"none\" points=\"267.5,-355.5 354.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311\" y=\"-340.3\">(None, 178)</text>\n</g>\n<!-- 140002906622776&#45;&gt;140002906682144 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140002906622776-&gt;140002906682144</title>\n<path d=\"M211.5,-415.3799C211.5,-407.1745 211.5,-397.7679 211.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-388.784 211.5,-378.784 208.0001,-388.784 215.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906242968 -->\n<g class=\"node\" id=\"node18\">\n<title>140002906242968</title>\n<polygon fill=\"none\" points=\"82,-249.5 82,-295.5 341,-295.5 341,-249.5 82,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-268.8\">dense_53: Dense</text>\n<polyline fill=\"none\" points=\"196,-249.5 196,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-272.5 254,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-249.5 254,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-280.3\">(None, 178)</text>\n<polyline fill=\"none\" points=\"254,-272.5 341,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-257.3\">(None, 91)</text>\n</g>\n<!-- 140002906682144&#45;&gt;140002906242968 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140002906682144-&gt;140002906242968</title>\n<path d=\"M211.5,-332.3799C211.5,-324.1745 211.5,-314.7679 211.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-305.784 211.5,-295.784 208.0001,-305.784 215.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002906266312 -->\n<g class=\"node\" id=\"node19\">\n<title>140002906266312</title>\n<polygon fill=\"none\" points=\"3.5,-166.5 3.5,-212.5 419.5,-212.5 419.5,-166.5 3.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-185.8\">batch_normalization_45: BatchNormalization</text>\n<polyline fill=\"none\" points=\"281.5,-166.5 281.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"281.5,-189.5 339.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"339.5,-166.5 339.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-197.3\">(None, 91)</text>\n<polyline fill=\"none\" points=\"339.5,-189.5 419.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-174.3\">(None, 91)</text>\n</g>\n<!-- 140002906242968&#45;&gt;140002906266312 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140002906242968-&gt;140002906266312</title>\n<path d=\"M211.5,-249.3799C211.5,-241.1745 211.5,-231.7679 211.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-222.784 211.5,-212.784 208.0001,-222.784 215.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002905956704 -->\n<g class=\"node\" id=\"node20\">\n<title>140002905956704</title>\n<polygon fill=\"none\" points=\"62,-83.5 62,-129.5 361,-129.5 361,-83.5 62,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-102.8\">activation_45: Activation</text>\n<polyline fill=\"none\" points=\"223,-83.5 223,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"223,-106.5 281,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"281,-83.5 281,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-114.3\">(None, 91)</text>\n<polyline fill=\"none\" points=\"281,-106.5 361,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-91.3\">(None, 91)</text>\n</g>\n<!-- 140002906266312&#45;&gt;140002905956704 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140002906266312-&gt;140002905956704</title>\n<path d=\"M211.5,-166.3799C211.5,-158.1745 211.5,-148.7679 211.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-139.784 211.5,-129.784 208.0001,-139.784 215.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140002905987448 -->\n<g class=\"node\" id=\"node21\">\n<title>140002905987448</title>\n<polygon fill=\"none\" points=\"85.5,-.5 85.5,-46.5 337.5,-46.5 337.5,-.5 85.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-19.8\">dense_54: Dense</text>\n<polyline fill=\"none\" points=\"199.5,-.5 199.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"199.5,-23.5 257.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"257.5,-.5 257.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-31.3\">(None, 91)</text>\n<polyline fill=\"none\" points=\"257.5,-23.5 337.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-8.3\">(None, 4)</text>\n</g>\n<!-- 140002905956704&#45;&gt;140002905987448 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140002905956704-&gt;140002905987448</title>\n<path d=\"M211.5,-83.3799C211.5,-75.1745 211.5,-65.7679 211.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.0001,-56.784 211.5,-46.784 208.0001,-56.784 215.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_mWcOE6vyUH",
        "colab_type": "code",
        "outputId": "165d62a7-616f-4eff-fe29-43ee96825954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# 학습 과정\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('mean absolute error')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEGCAYAAADIRPqpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwHpc7VvyZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예측값을 생성합니다.\n",
        "\n",
        "pred_test_09 = model_09.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDk6Qnu3vyfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission 파일을 생성합니다.\n",
        "sample_sub = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/sample_submission.csv', index_col=0)\n",
        "submission = sample_sub+pred_test_09\n",
        "submission.to_csv('/gdrive/My Drive/DACON-semiconductor-competition/submission_09.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}