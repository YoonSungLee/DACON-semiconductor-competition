{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submission_11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMF6hUzkd5hO1ZpIxBzYXy5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inha-AI/DACON-semiconductor-competition/blob/feature%2FYoonSungLee/submission_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBPfb1Jhq4TA",
        "colab_type": "code",
        "outputId": "a2ebf8dc-c5ad-4400-df67-098910ac1f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp36-none-any.whl size=10032 sha256=520115aa01aa5ac73972e5a42db3ffb9ac0089c154e1e7861878b0f4a2ed5880\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vVeUdyssBKw",
        "colab_type": "code",
        "outputId": "cebd4779-01e0-437a-b69a-034f4b579018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwHXDEigsNB0",
        "colab_type": "code",
        "outputId": "aa13539b-3f25-4396-bc58-1bfa4e8ee502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQF6BGGF1DqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 자료형을 적절히 변형시켜 데이터의 크기를 줄이는 방법\n",
        "\n",
        "# for col in df_train.columns:\n",
        "#     col_type = df_train[col].dtypes\n",
        "#     min1 = df_train[col].min()\n",
        "#     max1 = df_train[col].max()\n",
        "#     if str(col_type)[:3] == 'int':\n",
        "#         df_train[col] = df_train[col].astype(np.int16)\n",
        "#     else:\n",
        "#         if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n",
        "#             df_train[col] = trdf_trainain[col].astype(np.float16)\n",
        "#         elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n",
        "#             df_train[col] = df_train[col].astype(np.float32)\n",
        "#         else:\n",
        "#             df_train[col] = df_train[col].astype(np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BNXAU5rsPJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/train.csv')\n",
        "df_test = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdYXclfgsVr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 독립변수와 종속변수를 분리합니다.\n",
        "\n",
        "train_X = df_train.iloc[:,4:]\n",
        "train_Y = df_train.iloc[:,0:4]\n",
        "test_X = df_test.iloc[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogdcz8YctuVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train set을 shuffle하여 다시 train set과 validation set으로 분리합니다.\n",
        "\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tT4w6XasaSQ",
        "colab_type": "text"
      },
      "source": [
        "# Model 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PSSfoS5sfWK",
        "colab_type": "text"
      },
      "source": [
        "* 13 layers\n",
        "* (201, 176, 151, 126, 101, 76) units, he_normal, swish\n",
        "* BatchNormalization\n",
        "* Adam(0.001)\n",
        "* epochs 200\n",
        "* batch_size 630\n",
        "<br><br>\n",
        "* 총 13개의 layer를 쌓고 2개 단위로 양쪽 layer units의 평균을 해당 layer units으로 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGEkxH551LkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 케라스를 통해 모델 생성을 시작합니다.\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=201, input_dim=226, kernel_initializer='he_normal'))\n",
        "    model.add(Dense(units=201, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(swish))\n",
        "    model.add(Dense(units=176, kernel_initializer='he_normal'))\n",
        "    model.add(Dense(units=176, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(swish))\n",
        "    model.add(Dense(units=151, kernel_initializer='he_normal'))\n",
        "    model.add(Dense(units=151, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(swish))\n",
        "    model.add(Dense(units=126, kernel_initializer='he_normal'))\n",
        "    model.add(Dense(units=126, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(swish))\n",
        "    model.add(Dense(units=101, kernel_initializer='he_normal'))\n",
        "    model.add(Dense(units=101, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(swish))\n",
        "    model.add(Dense(units=76, kernel_initializer='he_normal'))\n",
        "    model.add(Dense(units=76, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(swish))\n",
        "    model.add(Dense(units=4, activation='linear'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Activation Function 정의\n",
        "\n",
        "def swish(x) :\n",
        "    return x * keras.activations.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35DQBYFkofR6",
        "colab_type": "code",
        "outputId": "4414366f-f335-4dc5-829e-22a9fc76019e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGFYnT9kW-6k",
        "colab_type": "code",
        "outputId": "c0ea1474-c13e-4787-c025-fcfc58b8dcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "adam = keras.optimizers.Adam(0.001)\n",
        "model.compile(loss='mae', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF7y-CDdW_AE",
        "colab_type": "code",
        "outputId": "c29c41f3-6181-4004-a58d-7a74ce6e5a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(train_X, train_Y, epochs=200, batch_size=630,\n",
        "                    validation_data=(val_X, val_Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 607500 samples, validate on 202500 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "607500/607500 [==============================] - 31s 50us/step - loss: 115.2130 - acc: 0.2407 - val_loss: 66.7795 - val_acc: 0.2403\n",
            "Epoch 2/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 53.1272 - acc: 0.3979 - val_loss: 45.2497 - val_acc: 0.5131\n",
            "Epoch 3/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 27.8829 - acc: 0.7100 - val_loss: 21.4209 - val_acc: 0.7861\n",
            "Epoch 4/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 16.8361 - acc: 0.8246 - val_loss: 16.8364 - val_acc: 0.8157\n",
            "Epoch 5/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 13.6288 - acc: 0.8574 - val_loss: 15.5329 - val_acc: 0.8313\n",
            "Epoch 6/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 11.9489 - acc: 0.8743 - val_loss: 11.5973 - val_acc: 0.8768\n",
            "Epoch 7/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 10.8815 - acc: 0.8847 - val_loss: 10.6621 - val_acc: 0.8853\n",
            "Epoch 8/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 10.0616 - acc: 0.8925 - val_loss: 10.4730 - val_acc: 0.8827\n",
            "Epoch 9/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 9.4389 - acc: 0.8987 - val_loss: 11.2876 - val_acc: 0.8727\n",
            "Epoch 10/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 8.9346 - acc: 0.9043 - val_loss: 9.2842 - val_acc: 0.8966\n",
            "Epoch 11/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 8.5202 - acc: 0.9079 - val_loss: 7.8855 - val_acc: 0.9117\n",
            "Epoch 12/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 8.2047 - acc: 0.9114 - val_loss: 7.7838 - val_acc: 0.9147\n",
            "Epoch 13/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 7.8655 - acc: 0.9141 - val_loss: 7.1843 - val_acc: 0.9185\n",
            "Epoch 14/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 7.6381 - acc: 0.9165 - val_loss: 7.9482 - val_acc: 0.9126\n",
            "Epoch 15/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 7.4030 - acc: 0.9192 - val_loss: 8.0479 - val_acc: 0.9121\n",
            "Epoch 16/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 7.1970 - acc: 0.9207 - val_loss: 6.9614 - val_acc: 0.9216\n",
            "Epoch 17/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 7.0133 - acc: 0.9229 - val_loss: 6.2122 - val_acc: 0.9334\n",
            "Epoch 18/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 6.8251 - acc: 0.9237 - val_loss: 6.6518 - val_acc: 0.9217\n",
            "Epoch 19/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 6.7121 - acc: 0.9250 - val_loss: 5.9971 - val_acc: 0.9289\n",
            "Epoch 20/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 6.5383 - acc: 0.9273 - val_loss: 6.0586 - val_acc: 0.9320\n",
            "Epoch 21/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 6.4388 - acc: 0.9282 - val_loss: 6.3080 - val_acc: 0.9307\n",
            "Epoch 22/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 6.3142 - acc: 0.9288 - val_loss: 6.2603 - val_acc: 0.9308\n",
            "Epoch 23/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 6.2100 - acc: 0.9304 - val_loss: 5.5347 - val_acc: 0.9261\n",
            "Epoch 24/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 6.0997 - acc: 0.9308 - val_loss: 5.3050 - val_acc: 0.9370\n",
            "Epoch 25/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 6.0077 - acc: 0.9322 - val_loss: 5.3200 - val_acc: 0.9401\n",
            "Epoch 26/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 5.8929 - acc: 0.9332 - val_loss: 5.2249 - val_acc: 0.9410\n",
            "Epoch 27/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 5.8207 - acc: 0.9335 - val_loss: 5.2927 - val_acc: 0.9411\n",
            "Epoch 28/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 5.7501 - acc: 0.9340 - val_loss: 5.2351 - val_acc: 0.9396\n",
            "Epoch 29/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 5.6516 - acc: 0.9351 - val_loss: 5.2040 - val_acc: 0.9370\n",
            "Epoch 30/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 5.5979 - acc: 0.9354 - val_loss: 5.0859 - val_acc: 0.9425\n",
            "Epoch 31/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 5.5530 - acc: 0.9360 - val_loss: 5.5270 - val_acc: 0.9333\n",
            "Epoch 32/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 5.4846 - acc: 0.9368 - val_loss: 4.8801 - val_acc: 0.9430\n",
            "Epoch 33/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 5.4125 - acc: 0.9373 - val_loss: 5.4339 - val_acc: 0.9389\n",
            "Epoch 34/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 5.3482 - acc: 0.9377 - val_loss: 5.2194 - val_acc: 0.9369\n",
            "Epoch 35/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 5.2864 - acc: 0.9387 - val_loss: 4.8114 - val_acc: 0.9436\n",
            "Epoch 36/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 5.2163 - acc: 0.9392 - val_loss: 4.8233 - val_acc: 0.9453\n",
            "Epoch 37/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 5.1665 - acc: 0.9397 - val_loss: 4.7145 - val_acc: 0.9449\n",
            "Epoch 38/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 5.1439 - acc: 0.9406 - val_loss: 4.8574 - val_acc: 0.9345\n",
            "Epoch 39/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 5.0957 - acc: 0.9400 - val_loss: 4.7435 - val_acc: 0.9417\n",
            "Epoch 40/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 5.0203 - acc: 0.9415 - val_loss: 5.0704 - val_acc: 0.9352\n",
            "Epoch 41/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 4.9673 - acc: 0.9419 - val_loss: 4.4627 - val_acc: 0.9486\n",
            "Epoch 42/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.9409 - acc: 0.9420 - val_loss: 4.4125 - val_acc: 0.9404\n",
            "Epoch 43/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 4.9167 - acc: 0.9420 - val_loss: 4.2526 - val_acc: 0.9534\n",
            "Epoch 44/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.8771 - acc: 0.9423 - val_loss: 4.4593 - val_acc: 0.9484\n",
            "Epoch 45/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 4.7936 - acc: 0.9437 - val_loss: 4.3126 - val_acc: 0.9510\n",
            "Epoch 46/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.8055 - acc: 0.9430 - val_loss: 4.4388 - val_acc: 0.9447\n",
            "Epoch 47/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.7636 - acc: 0.9441 - val_loss: 4.4238 - val_acc: 0.9504\n",
            "Epoch 48/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.7342 - acc: 0.9439 - val_loss: 4.6129 - val_acc: 0.9375\n",
            "Epoch 49/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.6908 - acc: 0.9444 - val_loss: 4.6434 - val_acc: 0.9441\n",
            "Epoch 50/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.6893 - acc: 0.9443 - val_loss: 4.2240 - val_acc: 0.9493\n",
            "Epoch 51/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 4.6144 - acc: 0.9454 - val_loss: 4.0181 - val_acc: 0.9565\n",
            "Epoch 52/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 4.5848 - acc: 0.9452 - val_loss: 4.0545 - val_acc: 0.9499\n",
            "Epoch 53/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 4.5438 - acc: 0.9456 - val_loss: 4.0035 - val_acc: 0.9526\n",
            "Epoch 54/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.5353 - acc: 0.9459 - val_loss: 4.1081 - val_acc: 0.9514\n",
            "Epoch 55/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.5099 - acc: 0.9460 - val_loss: 4.5048 - val_acc: 0.9487\n",
            "Epoch 56/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.5012 - acc: 0.9467 - val_loss: 4.0948 - val_acc: 0.9491\n",
            "Epoch 57/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.4442 - acc: 0.9467 - val_loss: 4.0257 - val_acc: 0.9479\n",
            "Epoch 58/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.4218 - acc: 0.9466 - val_loss: 3.8581 - val_acc: 0.9522\n",
            "Epoch 59/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.3726 - acc: 0.9472 - val_loss: 3.7343 - val_acc: 0.9485\n",
            "Epoch 60/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.3590 - acc: 0.9476 - val_loss: 3.7905 - val_acc: 0.9541\n",
            "Epoch 61/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.3584 - acc: 0.9471 - val_loss: 4.0077 - val_acc: 0.9449\n",
            "Epoch 62/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.3259 - acc: 0.9478 - val_loss: 3.8266 - val_acc: 0.9538\n",
            "Epoch 63/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.3040 - acc: 0.9477 - val_loss: 3.8352 - val_acc: 0.9498\n",
            "Epoch 64/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.2662 - acc: 0.9480 - val_loss: 3.8764 - val_acc: 0.9492\n",
            "Epoch 65/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 4.2755 - acc: 0.9481 - val_loss: 3.7734 - val_acc: 0.9555\n",
            "Epoch 66/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.2194 - acc: 0.9490 - val_loss: 3.7981 - val_acc: 0.9518\n",
            "Epoch 67/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 4.2173 - acc: 0.9487 - val_loss: 3.9197 - val_acc: 0.9505\n",
            "Epoch 68/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 4.1841 - acc: 0.9490 - val_loss: 3.8560 - val_acc: 0.9528\n",
            "Epoch 69/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 4.1746 - acc: 0.9490 - val_loss: 4.2743 - val_acc: 0.9412\n",
            "Epoch 70/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 4.1599 - acc: 0.9492 - val_loss: 3.7664 - val_acc: 0.9468\n",
            "Epoch 71/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 4.1405 - acc: 0.9494 - val_loss: 3.7339 - val_acc: 0.9560\n",
            "Epoch 72/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 4.1100 - acc: 0.9498 - val_loss: 3.7054 - val_acc: 0.9512\n",
            "Epoch 73/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 4.0812 - acc: 0.9499 - val_loss: 3.5431 - val_acc: 0.9501\n",
            "Epoch 74/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.0743 - acc: 0.9498 - val_loss: 3.5328 - val_acc: 0.9542\n",
            "Epoch 75/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.0333 - acc: 0.9503 - val_loss: 4.1436 - val_acc: 0.9478\n",
            "Epoch 76/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 4.0667 - acc: 0.9501 - val_loss: 3.3376 - val_acc: 0.9553\n",
            "Epoch 77/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 4.0271 - acc: 0.9503 - val_loss: 3.6403 - val_acc: 0.9515\n",
            "Epoch 78/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.9905 - acc: 0.9506 - val_loss: 3.7414 - val_acc: 0.9540\n",
            "Epoch 79/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 4.0041 - acc: 0.9505 - val_loss: 3.4978 - val_acc: 0.9524\n",
            "Epoch 80/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.9607 - acc: 0.9507 - val_loss: 3.6567 - val_acc: 0.9508\n",
            "Epoch 81/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.9249 - acc: 0.9513 - val_loss: 3.8919 - val_acc: 0.9511\n",
            "Epoch 82/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.9465 - acc: 0.9516 - val_loss: 3.4229 - val_acc: 0.9477\n",
            "Epoch 83/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.9257 - acc: 0.9512 - val_loss: 3.5196 - val_acc: 0.9556\n",
            "Epoch 84/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.9034 - acc: 0.9516 - val_loss: 3.3137 - val_acc: 0.9615\n",
            "Epoch 85/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.8933 - acc: 0.9516 - val_loss: 3.6882 - val_acc: 0.9573\n",
            "Epoch 86/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.8808 - acc: 0.9515 - val_loss: 3.3373 - val_acc: 0.9615\n",
            "Epoch 87/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.8530 - acc: 0.9516 - val_loss: 3.4227 - val_acc: 0.9510\n",
            "Epoch 88/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.8178 - acc: 0.9522 - val_loss: 3.1966 - val_acc: 0.9560\n",
            "Epoch 89/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.8258 - acc: 0.9522 - val_loss: 3.7450 - val_acc: 0.9515\n",
            "Epoch 90/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.8317 - acc: 0.9522 - val_loss: 3.4048 - val_acc: 0.9446\n",
            "Epoch 91/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.7885 - acc: 0.9520 - val_loss: 3.6267 - val_acc: 0.9500\n",
            "Epoch 92/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.8177 - acc: 0.9523 - val_loss: 3.3430 - val_acc: 0.9565\n",
            "Epoch 93/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.7764 - acc: 0.9525 - val_loss: 3.2469 - val_acc: 0.9562\n",
            "Epoch 94/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.7561 - acc: 0.9527 - val_loss: 3.2201 - val_acc: 0.9596\n",
            "Epoch 95/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.7445 - acc: 0.9525 - val_loss: 3.2090 - val_acc: 0.9545\n",
            "Epoch 96/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.7112 - acc: 0.9527 - val_loss: 3.4811 - val_acc: 0.9548\n",
            "Epoch 97/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.7243 - acc: 0.9530 - val_loss: 3.2268 - val_acc: 0.9542\n",
            "Epoch 98/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.7052 - acc: 0.9526 - val_loss: 3.1208 - val_acc: 0.9608\n",
            "Epoch 99/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.6989 - acc: 0.9529 - val_loss: 3.1517 - val_acc: 0.9547\n",
            "Epoch 100/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.6910 - acc: 0.9530 - val_loss: 2.9629 - val_acc: 0.9586\n",
            "Epoch 101/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.7020 - acc: 0.9529 - val_loss: 3.1930 - val_acc: 0.9615\n",
            "Epoch 102/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.6623 - acc: 0.9533 - val_loss: 3.3037 - val_acc: 0.9595\n",
            "Epoch 103/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.6484 - acc: 0.9534 - val_loss: 3.0846 - val_acc: 0.9589\n",
            "Epoch 104/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.6289 - acc: 0.9534 - val_loss: 3.2450 - val_acc: 0.9577\n",
            "Epoch 105/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.6498 - acc: 0.9534 - val_loss: 3.0916 - val_acc: 0.9590\n",
            "Epoch 106/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.6414 - acc: 0.9538 - val_loss: 2.9734 - val_acc: 0.9566\n",
            "Epoch 107/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.6194 - acc: 0.9537 - val_loss: 3.0720 - val_acc: 0.9625\n",
            "Epoch 108/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.6283 - acc: 0.9538 - val_loss: 3.2019 - val_acc: 0.9579\n",
            "Epoch 109/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5878 - acc: 0.9539 - val_loss: 2.9205 - val_acc: 0.9629\n",
            "Epoch 110/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.6005 - acc: 0.9540 - val_loss: 3.0081 - val_acc: 0.9508\n",
            "Epoch 111/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5744 - acc: 0.9538 - val_loss: 3.0203 - val_acc: 0.9587\n",
            "Epoch 112/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5595 - acc: 0.9542 - val_loss: 2.9197 - val_acc: 0.9628\n",
            "Epoch 113/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5503 - acc: 0.9544 - val_loss: 3.2271 - val_acc: 0.9588\n",
            "Epoch 114/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5579 - acc: 0.9541 - val_loss: 3.1801 - val_acc: 0.9534\n",
            "Epoch 115/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5401 - acc: 0.9541 - val_loss: 2.8927 - val_acc: 0.9654\n",
            "Epoch 116/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.5277 - acc: 0.9545 - val_loss: 3.0521 - val_acc: 0.9518\n",
            "Epoch 117/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5141 - acc: 0.9547 - val_loss: 3.0950 - val_acc: 0.9620\n",
            "Epoch 118/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.5186 - acc: 0.9545 - val_loss: 2.9077 - val_acc: 0.9586\n",
            "Epoch 119/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.4889 - acc: 0.9543 - val_loss: 2.9851 - val_acc: 0.9613\n",
            "Epoch 120/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.4916 - acc: 0.9549 - val_loss: 2.9357 - val_acc: 0.9556\n",
            "Epoch 121/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.4698 - acc: 0.9547 - val_loss: 2.9287 - val_acc: 0.9551\n",
            "Epoch 122/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4632 - acc: 0.9550 - val_loss: 2.8442 - val_acc: 0.9629\n",
            "Epoch 123/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4614 - acc: 0.9548 - val_loss: 3.1079 - val_acc: 0.9590\n",
            "Epoch 124/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4524 - acc: 0.9550 - val_loss: 2.8693 - val_acc: 0.9571\n",
            "Epoch 125/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4519 - acc: 0.9550 - val_loss: 3.0088 - val_acc: 0.9563\n",
            "Epoch 126/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4421 - acc: 0.9549 - val_loss: 3.0593 - val_acc: 0.9596\n",
            "Epoch 127/200\n",
            "607500/607500 [==============================] - 18s 29us/step - loss: 3.4351 - acc: 0.9555 - val_loss: 2.9546 - val_acc: 0.9563\n",
            "Epoch 128/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.4135 - acc: 0.9551 - val_loss: 2.9118 - val_acc: 0.9545\n",
            "Epoch 129/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4021 - acc: 0.9550 - val_loss: 2.9111 - val_acc: 0.9605\n",
            "Epoch 130/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.4051 - acc: 0.9550 - val_loss: 2.9417 - val_acc: 0.9596\n",
            "Epoch 131/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.4012 - acc: 0.9550 - val_loss: 2.8621 - val_acc: 0.9571\n",
            "Epoch 132/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.3915 - acc: 0.9552 - val_loss: 2.7845 - val_acc: 0.9571\n",
            "Epoch 133/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.3839 - acc: 0.9551 - val_loss: 2.9676 - val_acc: 0.9603\n",
            "Epoch 134/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.3848 - acc: 0.9558 - val_loss: 2.7635 - val_acc: 0.9625\n",
            "Epoch 135/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.3815 - acc: 0.9552 - val_loss: 2.7661 - val_acc: 0.9643\n",
            "Epoch 136/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.3602 - acc: 0.9555 - val_loss: 2.7548 - val_acc: 0.9615\n",
            "Epoch 137/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.3389 - acc: 0.9558 - val_loss: 2.7255 - val_acc: 0.9654\n",
            "Epoch 138/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.3426 - acc: 0.9556 - val_loss: 2.9035 - val_acc: 0.9654\n",
            "Epoch 139/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.3571 - acc: 0.9554 - val_loss: 2.8600 - val_acc: 0.9562\n",
            "Epoch 140/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.3340 - acc: 0.9558 - val_loss: 2.8354 - val_acc: 0.9572\n",
            "Epoch 141/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.3299 - acc: 0.9560 - val_loss: 2.7206 - val_acc: 0.9542\n",
            "Epoch 142/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.3266 - acc: 0.9557 - val_loss: 2.8836 - val_acc: 0.9622\n",
            "Epoch 143/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.3183 - acc: 0.9557 - val_loss: 3.0196 - val_acc: 0.9586\n",
            "Epoch 144/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.2973 - acc: 0.9562 - val_loss: 2.6226 - val_acc: 0.9611\n",
            "Epoch 145/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.3020 - acc: 0.9555 - val_loss: 2.7291 - val_acc: 0.9545\n",
            "Epoch 146/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2985 - acc: 0.9555 - val_loss: 2.7591 - val_acc: 0.9615\n",
            "Epoch 147/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.2911 - acc: 0.9560 - val_loss: 2.7677 - val_acc: 0.9566\n",
            "Epoch 148/200\n",
            "607500/607500 [==============================] - 21s 35us/step - loss: 3.2875 - acc: 0.9557 - val_loss: 2.7412 - val_acc: 0.9630\n",
            "Epoch 149/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.2777 - acc: 0.9560 - val_loss: 2.8200 - val_acc: 0.9569\n",
            "Epoch 150/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2739 - acc: 0.9560 - val_loss: 2.8687 - val_acc: 0.9558\n",
            "Epoch 151/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.2637 - acc: 0.9564 - val_loss: 2.6130 - val_acc: 0.9604\n",
            "Epoch 152/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.2422 - acc: 0.9563 - val_loss: 2.7512 - val_acc: 0.9614\n",
            "Epoch 153/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2546 - acc: 0.9565 - val_loss: 2.8911 - val_acc: 0.9628\n",
            "Epoch 154/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2462 - acc: 0.9563 - val_loss: 3.0969 - val_acc: 0.9604\n",
            "Epoch 155/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2400 - acc: 0.9564 - val_loss: 2.7115 - val_acc: 0.9610\n",
            "Epoch 156/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2212 - acc: 0.9562 - val_loss: 2.6999 - val_acc: 0.9562\n",
            "Epoch 157/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.2365 - acc: 0.9564 - val_loss: 2.8342 - val_acc: 0.9612\n",
            "Epoch 158/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 3.2240 - acc: 0.9565 - val_loss: 2.7583 - val_acc: 0.9589\n",
            "Epoch 159/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.2186 - acc: 0.9566 - val_loss: 2.6503 - val_acc: 0.9642\n",
            "Epoch 160/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 3.1991 - acc: 0.9567 - val_loss: 2.6105 - val_acc: 0.9600\n",
            "Epoch 161/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.1949 - acc: 0.9569 - val_loss: 2.5932 - val_acc: 0.9629\n",
            "Epoch 162/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 3.1867 - acc: 0.9569 - val_loss: 2.5404 - val_acc: 0.9612\n",
            "Epoch 163/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 3.1858 - acc: 0.9564 - val_loss: 2.7118 - val_acc: 0.9632\n",
            "Epoch 164/200\n",
            "607500/607500 [==============================] - 20s 34us/step - loss: 3.1675 - acc: 0.9569 - val_loss: 2.6364 - val_acc: 0.9656\n",
            "Epoch 165/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.1992 - acc: 0.9568 - val_loss: 2.6828 - val_acc: 0.9621\n",
            "Epoch 166/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.1991 - acc: 0.9564 - val_loss: 2.6159 - val_acc: 0.9567\n",
            "Epoch 167/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.1696 - acc: 0.9565 - val_loss: 2.6319 - val_acc: 0.9668\n",
            "Epoch 168/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.1684 - acc: 0.9566 - val_loss: 2.5369 - val_acc: 0.9631\n",
            "Epoch 169/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.1509 - acc: 0.9567 - val_loss: 2.7142 - val_acc: 0.9599\n",
            "Epoch 170/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.1549 - acc: 0.9568 - val_loss: 2.8005 - val_acc: 0.9648\n",
            "Epoch 171/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.1489 - acc: 0.9570 - val_loss: 2.6020 - val_acc: 0.9593\n",
            "Epoch 172/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.1619 - acc: 0.9568 - val_loss: 2.8642 - val_acc: 0.9614\n",
            "Epoch 173/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.1314 - acc: 0.9568 - val_loss: 2.5430 - val_acc: 0.9644\n",
            "Epoch 174/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.1356 - acc: 0.9570 - val_loss: 2.6506 - val_acc: 0.9599\n",
            "Epoch 175/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.1215 - acc: 0.9571 - val_loss: 2.7390 - val_acc: 0.9556\n",
            "Epoch 176/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.1401 - acc: 0.9568 - val_loss: 2.5112 - val_acc: 0.9612\n",
            "Epoch 177/200\n",
            "607500/607500 [==============================] - 19s 30us/step - loss: 3.1106 - acc: 0.9572 - val_loss: 2.5241 - val_acc: 0.9602\n",
            "Epoch 178/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.1114 - acc: 0.9572 - val_loss: 2.6592 - val_acc: 0.9590\n",
            "Epoch 179/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.1261 - acc: 0.9572 - val_loss: 2.6829 - val_acc: 0.9580\n",
            "Epoch 180/200\n",
            "607500/607500 [==============================] - 18s 30us/step - loss: 3.0951 - acc: 0.9574 - val_loss: 2.5001 - val_acc: 0.9587\n",
            "Epoch 181/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.1103 - acc: 0.9571 - val_loss: 2.6639 - val_acc: 0.9559\n",
            "Epoch 182/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.1099 - acc: 0.9574 - val_loss: 2.5885 - val_acc: 0.9586\n",
            "Epoch 183/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0866 - acc: 0.9573 - val_loss: 2.6342 - val_acc: 0.9629\n",
            "Epoch 184/200\n",
            "607500/607500 [==============================] - 19s 32us/step - loss: 3.0977 - acc: 0.9570 - val_loss: 2.5465 - val_acc: 0.9642\n",
            "Epoch 185/200\n",
            "607500/607500 [==============================] - 19s 31us/step - loss: 3.0854 - acc: 0.9571 - val_loss: 2.5144 - val_acc: 0.9641\n",
            "Epoch 186/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0822 - acc: 0.9577 - val_loss: 2.5834 - val_acc: 0.9575\n",
            "Epoch 187/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.0751 - acc: 0.9574 - val_loss: 2.5411 - val_acc: 0.9632\n",
            "Epoch 188/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0778 - acc: 0.9572 - val_loss: 2.5076 - val_acc: 0.9656\n",
            "Epoch 189/200\n",
            "607500/607500 [==============================] - 20s 32us/step - loss: 3.0616 - acc: 0.9575 - val_loss: 2.6755 - val_acc: 0.9619\n",
            "Epoch 190/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0647 - acc: 0.9575 - val_loss: 2.6867 - val_acc: 0.9638\n",
            "Epoch 191/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0687 - acc: 0.9574 - val_loss: 2.6815 - val_acc: 0.9578\n",
            "Epoch 192/200\n",
            "607500/607500 [==============================] - 21s 34us/step - loss: 3.0657 - acc: 0.9571 - val_loss: 2.5724 - val_acc: 0.9644\n",
            "Epoch 193/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0638 - acc: 0.9574 - val_loss: 2.5441 - val_acc: 0.9633\n",
            "Epoch 194/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0577 - acc: 0.9577 - val_loss: 2.4820 - val_acc: 0.9619\n",
            "Epoch 195/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0524 - acc: 0.9579 - val_loss: 2.4327 - val_acc: 0.9657\n",
            "Epoch 196/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0295 - acc: 0.9580 - val_loss: 2.4774 - val_acc: 0.9570\n",
            "Epoch 197/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0412 - acc: 0.9578 - val_loss: 2.5142 - val_acc: 0.9599\n",
            "Epoch 198/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0347 - acc: 0.9577 - val_loss: 2.5529 - val_acc: 0.9567\n",
            "Epoch 199/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0255 - acc: 0.9577 - val_loss: 2.5090 - val_acc: 0.9634\n",
            "Epoch 200/200\n",
            "607500/607500 [==============================] - 20s 33us/step - loss: 3.0189 - acc: 0.9578 - val_loss: 2.5236 - val_acc: 0.9589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsfen6zmofgX",
        "colab_type": "code",
        "outputId": "5fb9d16b-3dc6-4e43-ab87-58fa293ce375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 모델 아키텍처\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"2840pt\" viewBox=\"0.00 0.00 424.00 2130.00\" width=\"565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 2126)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-2126 420,-2126 420,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140326921068496 -->\n<g class=\"node\" id=\"node1\">\n<title>140326921068496</title>\n<polygon fill=\"none\" points=\"49,-2075.5 49,-2121.5 367,-2121.5 367,-2075.5 49,-2075.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-2094.8\">dense_1_input: InputLayer</text>\n<polyline fill=\"none\" points=\"222,-2075.5 222,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"251\" y=\"-2106.3\">input:</text>\n<polyline fill=\"none\" points=\"222,-2098.5 280,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"251\" y=\"-2083.3\">output:</text>\n<polyline fill=\"none\" points=\"280,-2075.5 280,-2121.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323.5\" y=\"-2106.3\">(None, 226)</text>\n<polyline fill=\"none\" points=\"280,-2098.5 367,-2098.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323.5\" y=\"-2083.3\">(None, 226)</text>\n</g>\n<!-- 140326921068440 -->\n<g class=\"node\" id=\"node2\">\n<title>140326921068440</title>\n<polygon fill=\"none\" points=\"82,-1992.5 82,-2038.5 334,-2038.5 334,-1992.5 82,-1992.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-2011.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"189,-1992.5 189,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-2023.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-2015.5 247,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-2000.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-1992.5 247,-2038.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-2023.3\">(None, 226)</text>\n<polyline fill=\"none\" points=\"247,-2015.5 334,-2015.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-2000.3\">(None, 201)</text>\n</g>\n<!-- 140326921068496&#45;&gt;140326921068440 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140326921068496-&gt;140326921068440</title>\n<path d=\"M208,-2075.3799C208,-2067.1745 208,-2057.7679 208,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-2048.784 208,-2038.784 204.5001,-2048.784 211.5001,-2048.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326917972600 -->\n<g class=\"node\" id=\"node3\">\n<title>140326917972600</title>\n<polygon fill=\"none\" points=\"82,-1909.5 82,-1955.5 334,-1955.5 334,-1909.5 82,-1909.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1928.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"189,-1909.5 189,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1940.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-1932.5 247,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1917.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-1909.5 247,-1955.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1940.3\">(None, 201)</text>\n<polyline fill=\"none\" points=\"247,-1932.5 334,-1932.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1917.3\">(None, 201)</text>\n</g>\n<!-- 140326921068440&#45;&gt;140326917972600 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140326921068440-&gt;140326917972600</title>\n<path d=\"M208,-1992.3799C208,-1984.1745 208,-1974.7679 208,-1965.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1965.784 208,-1955.784 204.5001,-1965.784 211.5001,-1965.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326917886528 -->\n<g class=\"node\" id=\"node4\">\n<title>140326917886528</title>\n<polygon fill=\"none\" points=\"0,-1826.5 0,-1872.5 416,-1872.5 416,-1826.5 0,-1826.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1845.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-1826.5 271,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-1857.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-1849.5 329,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-1834.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-1826.5 329,-1872.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1857.3\">(None, 201)</text>\n<polyline fill=\"none\" points=\"329,-1849.5 416,-1849.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1834.3\">(None, 201)</text>\n</g>\n<!-- 140326917972600&#45;&gt;140326917886528 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140326917972600-&gt;140326917886528</title>\n<path d=\"M208,-1909.3799C208,-1901.1745 208,-1891.7679 208,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1882.784 208,-1872.784 204.5001,-1882.784 211.5001,-1882.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326918098112 -->\n<g class=\"node\" id=\"node5\">\n<title>140326918098112</title>\n<polygon fill=\"none\" points=\"58.5,-1743.5 58.5,-1789.5 357.5,-1789.5 357.5,-1743.5 58.5,-1743.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1762.8\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"212.5,-1743.5 212.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-1774.3\">input:</text>\n<polyline fill=\"none\" points=\"212.5,-1766.5 270.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-1751.3\">output:</text>\n<polyline fill=\"none\" points=\"270.5,-1743.5 270.5,-1789.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-1774.3\">(None, 201)</text>\n<polyline fill=\"none\" points=\"270.5,-1766.5 357.5,-1766.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-1751.3\">(None, 201)</text>\n</g>\n<!-- 140326917886528&#45;&gt;140326918098112 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140326917886528-&gt;140326918098112</title>\n<path d=\"M208,-1826.3799C208,-1818.1745 208,-1808.7679 208,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1799.784 208,-1789.784 204.5001,-1799.784 211.5001,-1799.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326917411448 -->\n<g class=\"node\" id=\"node6\">\n<title>140326917411448</title>\n<polygon fill=\"none\" points=\"82,-1660.5 82,-1706.5 334,-1706.5 334,-1660.5 82,-1660.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1679.8\">dense_3: Dense</text>\n<polyline fill=\"none\" points=\"189,-1660.5 189,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1691.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-1683.5 247,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1668.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-1660.5 247,-1706.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1691.3\">(None, 201)</text>\n<polyline fill=\"none\" points=\"247,-1683.5 334,-1683.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1668.3\">(None, 176)</text>\n</g>\n<!-- 140326918098112&#45;&gt;140326917411448 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140326918098112-&gt;140326917411448</title>\n<path d=\"M208,-1743.3799C208,-1735.1745 208,-1725.7679 208,-1716.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1716.784 208,-1706.784 204.5001,-1716.784 211.5001,-1716.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326917563112 -->\n<g class=\"node\" id=\"node7\">\n<title>140326917563112</title>\n<polygon fill=\"none\" points=\"82,-1577.5 82,-1623.5 334,-1623.5 334,-1577.5 82,-1577.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1596.8\">dense_4: Dense</text>\n<polyline fill=\"none\" points=\"189,-1577.5 189,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1608.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-1600.5 247,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1585.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-1577.5 247,-1623.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1608.3\">(None, 176)</text>\n<polyline fill=\"none\" points=\"247,-1600.5 334,-1600.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1585.3\">(None, 176)</text>\n</g>\n<!-- 140326917411448&#45;&gt;140326917563112 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140326917411448-&gt;140326917563112</title>\n<path d=\"M208,-1660.3799C208,-1652.1745 208,-1642.7679 208,-1633.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1633.784 208,-1623.784 204.5001,-1633.784 211.5001,-1633.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920795976 -->\n<g class=\"node\" id=\"node8\">\n<title>140326920795976</title>\n<polygon fill=\"none\" points=\"0,-1494.5 0,-1540.5 416,-1540.5 416,-1494.5 0,-1494.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1513.8\">batch_normalization_2: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-1494.5 271,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-1525.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-1517.5 329,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-1502.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-1494.5 329,-1540.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1525.3\">(None, 176)</text>\n<polyline fill=\"none\" points=\"329,-1517.5 416,-1517.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1502.3\">(None, 176)</text>\n</g>\n<!-- 140326917563112&#45;&gt;140326920795976 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140326917563112-&gt;140326920795976</title>\n<path d=\"M208,-1577.3799C208,-1569.1745 208,-1559.7679 208,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1550.784 208,-1540.784 204.5001,-1550.784 211.5001,-1550.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920822400 -->\n<g class=\"node\" id=\"node9\">\n<title>140326920822400</title>\n<polygon fill=\"none\" points=\"58.5,-1411.5 58.5,-1457.5 357.5,-1457.5 357.5,-1411.5 58.5,-1411.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1430.8\">activation_2: Activation</text>\n<polyline fill=\"none\" points=\"212.5,-1411.5 212.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-1442.3\">input:</text>\n<polyline fill=\"none\" points=\"212.5,-1434.5 270.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-1419.3\">output:</text>\n<polyline fill=\"none\" points=\"270.5,-1411.5 270.5,-1457.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-1442.3\">(None, 176)</text>\n<polyline fill=\"none\" points=\"270.5,-1434.5 357.5,-1434.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-1419.3\">(None, 176)</text>\n</g>\n<!-- 140326920795976&#45;&gt;140326920822400 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140326920795976-&gt;140326920822400</title>\n<path d=\"M208,-1494.3799C208,-1486.1745 208,-1476.7679 208,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1467.784 208,-1457.784 204.5001,-1467.784 211.5001,-1467.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920807872 -->\n<g class=\"node\" id=\"node10\">\n<title>140326920807872</title>\n<polygon fill=\"none\" points=\"82,-1328.5 82,-1374.5 334,-1374.5 334,-1328.5 82,-1328.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1347.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"189,-1328.5 189,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1359.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-1351.5 247,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1336.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-1328.5 247,-1374.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1359.3\">(None, 176)</text>\n<polyline fill=\"none\" points=\"247,-1351.5 334,-1351.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1336.3\">(None, 151)</text>\n</g>\n<!-- 140326920822400&#45;&gt;140326920807872 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140326920822400-&gt;140326920807872</title>\n<path d=\"M208,-1411.3799C208,-1403.1745 208,-1393.7679 208,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1384.784 208,-1374.784 204.5001,-1384.784 211.5001,-1384.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920551952 -->\n<g class=\"node\" id=\"node11\">\n<title>140326920551952</title>\n<polygon fill=\"none\" points=\"82,-1245.5 82,-1291.5 334,-1291.5 334,-1245.5 82,-1245.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1264.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"189,-1245.5 189,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1276.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-1268.5 247,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1253.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-1245.5 247,-1291.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1276.3\">(None, 151)</text>\n<polyline fill=\"none\" points=\"247,-1268.5 334,-1268.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1253.3\">(None, 151)</text>\n</g>\n<!-- 140326920807872&#45;&gt;140326920551952 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140326920807872-&gt;140326920551952</title>\n<path d=\"M208,-1328.3799C208,-1320.1745 208,-1310.7679 208,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1301.784 208,-1291.784 204.5001,-1301.784 211.5001,-1301.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920607672 -->\n<g class=\"node\" id=\"node12\">\n<title>140326920607672</title>\n<polygon fill=\"none\" points=\"0,-1162.5 0,-1208.5 416,-1208.5 416,-1162.5 0,-1162.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1181.8\">batch_normalization_3: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-1162.5 271,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-1193.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-1185.5 329,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-1170.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-1162.5 329,-1208.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1193.3\">(None, 151)</text>\n<polyline fill=\"none\" points=\"329,-1185.5 416,-1185.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-1170.3\">(None, 151)</text>\n</g>\n<!-- 140326920551952&#45;&gt;140326920607672 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140326920551952-&gt;140326920607672</title>\n<path d=\"M208,-1245.3799C208,-1237.1745 208,-1227.7679 208,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1218.784 208,-1208.784 204.5001,-1218.784 211.5001,-1218.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920638024 -->\n<g class=\"node\" id=\"node13\">\n<title>140326920638024</title>\n<polygon fill=\"none\" points=\"58.5,-1079.5 58.5,-1125.5 357.5,-1125.5 357.5,-1079.5 58.5,-1079.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1098.8\">activation_3: Activation</text>\n<polyline fill=\"none\" points=\"212.5,-1079.5 212.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-1110.3\">input:</text>\n<polyline fill=\"none\" points=\"212.5,-1102.5 270.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-1087.3\">output:</text>\n<polyline fill=\"none\" points=\"270.5,-1079.5 270.5,-1125.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-1110.3\">(None, 151)</text>\n<polyline fill=\"none\" points=\"270.5,-1102.5 357.5,-1102.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-1087.3\">(None, 151)</text>\n</g>\n<!-- 140326920607672&#45;&gt;140326920638024 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140326920607672-&gt;140326920638024</title>\n<path d=\"M208,-1162.3799C208,-1154.1745 208,-1144.7679 208,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1135.784 208,-1125.784 204.5001,-1135.784 211.5001,-1135.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920663784 -->\n<g class=\"node\" id=\"node14\">\n<title>140326920663784</title>\n<polygon fill=\"none\" points=\"82,-996.5 82,-1042.5 334,-1042.5 334,-996.5 82,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-1015.8\">dense_7: Dense</text>\n<polyline fill=\"none\" points=\"189,-996.5 189,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-1019.5 247,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-996.5 247,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1027.3\">(None, 151)</text>\n<polyline fill=\"none\" points=\"247,-1019.5 334,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-1004.3\">(None, 126)</text>\n</g>\n<!-- 140326920638024&#45;&gt;140326920663784 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140326920638024-&gt;140326920663784</title>\n<path d=\"M208,-1079.3799C208,-1071.1745 208,-1061.7679 208,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-1052.784 208,-1042.784 204.5001,-1052.784 211.5001,-1052.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920359216 -->\n<g class=\"node\" id=\"node15\">\n<title>140326920359216</title>\n<polygon fill=\"none\" points=\"82,-913.5 82,-959.5 334,-959.5 334,-913.5 82,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-932.8\">dense_8: Dense</text>\n<polyline fill=\"none\" points=\"189,-913.5 189,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-936.5 247,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-913.5 247,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-944.3\">(None, 126)</text>\n<polyline fill=\"none\" points=\"247,-936.5 334,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-921.3\">(None, 126)</text>\n</g>\n<!-- 140326920663784&#45;&gt;140326920359216 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140326920663784-&gt;140326920359216</title>\n<path d=\"M208,-996.3799C208,-988.1745 208,-978.7679 208,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-969.784 208,-959.784 204.5001,-969.784 211.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920420208 -->\n<g class=\"node\" id=\"node16\">\n<title>140326920420208</title>\n<polygon fill=\"none\" points=\"0,-830.5 0,-876.5 416,-876.5 416,-830.5 0,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-849.8\">batch_normalization_4: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-830.5 271,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-853.5 329,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-830.5 329,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-861.3\">(None, 126)</text>\n<polyline fill=\"none\" points=\"329,-853.5 416,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-838.3\">(None, 126)</text>\n</g>\n<!-- 140326920359216&#45;&gt;140326920420208 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140326920359216-&gt;140326920420208</title>\n<path d=\"M208,-913.3799C208,-905.1745 208,-895.7679 208,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-886.784 208,-876.784 204.5001,-886.784 211.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920449832 -->\n<g class=\"node\" id=\"node17\">\n<title>140326920449832</title>\n<polygon fill=\"none\" points=\"58.5,-747.5 58.5,-793.5 357.5,-793.5 357.5,-747.5 58.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-766.8\">activation_4: Activation</text>\n<polyline fill=\"none\" points=\"212.5,-747.5 212.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"212.5,-770.5 270.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"270.5,-747.5 270.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-778.3\">(None, 126)</text>\n<polyline fill=\"none\" points=\"270.5,-770.5 357.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-755.3\">(None, 126)</text>\n</g>\n<!-- 140326920420208&#45;&gt;140326920449832 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140326920420208-&gt;140326920449832</title>\n<path d=\"M208,-830.3799C208,-822.1745 208,-812.7679 208,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-803.784 208,-793.784 204.5001,-803.784 211.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920480248 -->\n<g class=\"node\" id=\"node18\">\n<title>140326920480248</title>\n<polygon fill=\"none\" points=\"82,-664.5 82,-710.5 334,-710.5 334,-664.5 82,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-683.8\">dense_9: Dense</text>\n<polyline fill=\"none\" points=\"189,-664.5 189,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"189,-687.5 247,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"247,-664.5 247,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-695.3\">(None, 126)</text>\n<polyline fill=\"none\" points=\"247,-687.5 334,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290.5\" y=\"-672.3\">(None, 101)</text>\n</g>\n<!-- 140326920449832&#45;&gt;140326920480248 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140326920449832-&gt;140326920480248</title>\n<path d=\"M208,-747.3799C208,-739.1745 208,-729.7679 208,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-720.784 208,-710.784 204.5001,-720.784 211.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920183312 -->\n<g class=\"node\" id=\"node19\">\n<title>140326920183312</title>\n<polygon fill=\"none\" points=\"78.5,-581.5 78.5,-627.5 337.5,-627.5 337.5,-581.5 78.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-600.8\">dense_10: Dense</text>\n<polyline fill=\"none\" points=\"192.5,-581.5 192.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"192.5,-604.5 250.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"250.5,-581.5 250.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-612.3\">(None, 101)</text>\n<polyline fill=\"none\" points=\"250.5,-604.5 337.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-589.3\">(None, 101)</text>\n</g>\n<!-- 140326920480248&#45;&gt;140326920183312 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140326920480248-&gt;140326920183312</title>\n<path d=\"M208,-664.3799C208,-656.1745 208,-646.7679 208,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-637.784 208,-627.784 204.5001,-637.784 211.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326919729048 -->\n<g class=\"node\" id=\"node20\">\n<title>140326919729048</title>\n<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 416,-544.5 416,-498.5 0,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-517.8\">batch_normalization_5: BatchNormalization</text>\n<polyline fill=\"none\" points=\"271,-498.5 271,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"271,-521.5 329,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"300\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"329,-498.5 329,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-529.3\">(None, 101)</text>\n<polyline fill=\"none\" points=\"329,-521.5 416,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-506.3\">(None, 101)</text>\n</g>\n<!-- 140326920183312&#45;&gt;140326919729048 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140326920183312-&gt;140326919729048</title>\n<path d=\"M208,-581.3799C208,-573.1745 208,-563.7679 208,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-554.784 208,-544.784 204.5001,-554.784 211.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326919746168 -->\n<g class=\"node\" id=\"node21\">\n<title>140326919746168</title>\n<polygon fill=\"none\" points=\"58.5,-415.5 58.5,-461.5 357.5,-461.5 357.5,-415.5 58.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-434.8\">activation_5: Activation</text>\n<polyline fill=\"none\" points=\"212.5,-415.5 212.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"212.5,-438.5 270.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"270.5,-415.5 270.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-446.3\">(None, 101)</text>\n<polyline fill=\"none\" points=\"270.5,-438.5 357.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-423.3\">(None, 101)</text>\n</g>\n<!-- 140326919729048&#45;&gt;140326919746168 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140326919729048-&gt;140326919746168</title>\n<path d=\"M208,-498.3799C208,-490.1745 208,-480.7679 208,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-471.784 208,-461.784 204.5001,-471.784 211.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326919779216 -->\n<g class=\"node\" id=\"node22\">\n<title>140326919779216</title>\n<polygon fill=\"none\" points=\"79,-332.5 79,-378.5 337,-378.5 337,-332.5 79,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135.5\" y=\"-351.8\">dense_11: Dense</text>\n<polyline fill=\"none\" points=\"192,-332.5 192,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"192,-355.5 250,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"250,-332.5 250,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-363.3\">(None, 101)</text>\n<polyline fill=\"none\" points=\"250,-355.5 337,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"293.5\" y=\"-340.3\">(None, 76)</text>\n</g>\n<!-- 140326919746168&#45;&gt;140326919779216 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140326919746168-&gt;140326919779216</title>\n<path d=\"M208,-415.3799C208,-407.1745 208,-397.7679 208,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-388.784 208,-378.784 204.5001,-388.784 211.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326919884248 -->\n<g class=\"node\" id=\"node23\">\n<title>140326919884248</title>\n<polygon fill=\"none\" points=\"82,-249.5 82,-295.5 334,-295.5 334,-249.5 82,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-268.8\">dense_12: Dense</text>\n<polyline fill=\"none\" points=\"196,-249.5 196,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-272.5 254,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-249.5 254,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-280.3\">(None, 76)</text>\n<polyline fill=\"none\" points=\"254,-272.5 334,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-257.3\">(None, 76)</text>\n</g>\n<!-- 140326919779216&#45;&gt;140326919884248 -->\n<g class=\"edge\" id=\"edge22\">\n<title>140326919779216-&gt;140326919884248</title>\n<path d=\"M208,-332.3799C208,-324.1745 208,-314.7679 208,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-305.784 208,-295.784 204.5001,-305.784 211.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326919562632 -->\n<g class=\"node\" id=\"node24\">\n<title>140326919562632</title>\n<polygon fill=\"none\" points=\"3.5,-166.5 3.5,-212.5 412.5,-212.5 412.5,-166.5 3.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-185.8\">batch_normalization_6: BatchNormalization</text>\n<polyline fill=\"none\" points=\"274.5,-166.5 274.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"274.5,-189.5 332.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"332.5,-166.5 332.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-197.3\">(None, 76)</text>\n<polyline fill=\"none\" points=\"332.5,-189.5 412.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-174.3\">(None, 76)</text>\n</g>\n<!-- 140326919884248&#45;&gt;140326919562632 -->\n<g class=\"edge\" id=\"edge23\">\n<title>140326919884248-&gt;140326919562632</title>\n<path d=\"M208,-249.3799C208,-241.1745 208,-231.7679 208,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-222.784 208,-212.784 204.5001,-222.784 211.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326919562016 -->\n<g class=\"node\" id=\"node25\">\n<title>140326919562016</title>\n<polygon fill=\"none\" points=\"62,-83.5 62,-129.5 354,-129.5 354,-83.5 62,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-102.8\">activation_6: Activation</text>\n<polyline fill=\"none\" points=\"216,-83.5 216,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"216,-106.5 274,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"274,-83.5 274,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-114.3\">(None, 76)</text>\n<polyline fill=\"none\" points=\"274,-106.5 354,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"314\" y=\"-91.3\">(None, 76)</text>\n</g>\n<!-- 140326919562632&#45;&gt;140326919562016 -->\n<g class=\"edge\" id=\"edge24\">\n<title>140326919562632-&gt;140326919562016</title>\n<path d=\"M208,-166.3799C208,-158.1745 208,-148.7679 208,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-139.784 208,-129.784 204.5001,-139.784 211.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140326920238192 -->\n<g class=\"node\" id=\"node26\">\n<title>140326920238192</title>\n<polygon fill=\"none\" points=\"82,-.5 82,-46.5 334,-46.5 334,-.5 82,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-19.8\">dense_13: Dense</text>\n<polyline fill=\"none\" points=\"196,-.5 196,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-23.5 254,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-.5 254,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-31.3\">(None, 76)</text>\n<polyline fill=\"none\" points=\"254,-23.5 334,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-8.3\">(None, 4)</text>\n</g>\n<!-- 140326919562016&#45;&gt;140326920238192 -->\n<g class=\"edge\" id=\"edge25\">\n<title>140326919562016-&gt;140326920238192</title>\n<path d=\"M208,-83.3799C208,-75.1745 208,-65.7679 208,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"211.5001,-56.784 208,-46.784 204.5001,-56.784 211.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtD82zROogDP",
        "colab_type": "code",
        "outputId": "2c49335b-1902-4120-9df3-88885807289c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# 학습 과정\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('mean absolute error')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEJCAYAAADFB2O2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlWEYhhFq/h/xdfoKE7cafQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRMuL2mFogIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예측값을 생성합니다.\n",
        "\n",
        "pred_test = model.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv6yp_Hzoq4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission 파일을 생성합니다.\n",
        "sample_sub = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/sample_submission.csv', index_col=0)\n",
        "submission = sample_sub+pred_test\n",
        "submission.to_csv('/gdrive/My Drive/DACON-semiconductor-competition/submission_11.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0160k5JKnipA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습된 모델을 저장합니다.\n",
        "\n",
        "model.save('/gdrive/My Drive/DACON-semiconductor-competition/model_11.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IaqhJqmV_5",
        "colab_type": "text"
      },
      "source": [
        "### Bayesian Optimization\n",
        "http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html<br>\n",
        "http://research.sualab.com/introduction/practice/2019/04/01/bayesian-optimization-overview-2.html<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNwDuaRWmWg4",
        "colab_type": "text"
      },
      "source": [
        "### Swish Activation\n",
        "https://www.machinecurve.com/index.php/2019/05/30/why-swish-could-perform-better-than-relu/#todays-activation-functions"
      ]
    }
  ]
}