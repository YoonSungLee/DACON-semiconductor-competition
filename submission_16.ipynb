{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submission_16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhG0nc2myvAI0645Tw2o9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inha-AI/DACON-semiconductor-competition/blob/feature%2FYoonSungLee/submission_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBPfb1Jhq4TA",
        "colab_type": "code",
        "outputId": "58817d6f-cea3-44d9-a61a-b5630e7b34cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp36-none-any.whl size=10032 sha256=85647bcf12d9ab5a77163421fa0229c7d01d1a03f19d1ececa26092efaff7544\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vVeUdyssBKw",
        "colab_type": "code",
        "outputId": "4768f0c9-cd26-4d90-d425-9f9ec69cb948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwHXDEigsNB0",
        "colab_type": "code",
        "outputId": "5d4ea48f-e850-4a95-8781-d1af73ff664c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQF6BGGF1DqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 자료형을 적절히 변형시켜 데이터의 크기를 줄이는 방법\n",
        "\n",
        "# for col in df_train.columns:\n",
        "#     col_type = df_train[col].dtypes\n",
        "#     min1 = df_train[col].min()\n",
        "#     max1 = df_train[col].max()\n",
        "#     if str(col_type)[:3] == 'int':\n",
        "#         df_train[col] = df_train[col].astype(np.int16)\n",
        "#     else:\n",
        "#         if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n",
        "#             df_train[col] = trdf_trainain[col].astype(np.float16)\n",
        "#         elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n",
        "#             df_train[col] = df_train[col].astype(np.float32)\n",
        "#         else:\n",
        "#             df_train[col] = df_train[col].astype(np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BNXAU5rsPJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/train.csv')\n",
        "df_test = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdYXclfgsVr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 독립변수와 종속변수를 분리합니다.\n",
        "\n",
        "train_X = df_train.iloc[:,4:]\n",
        "train_Y = df_train.iloc[:,0:4]\n",
        "test_X = df_test.iloc[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogdcz8YctuVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train set을 shuffle하여 다시 train set과 validation set으로 분리합니다.\n",
        "\n",
        "# train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tT4w6XasaSQ",
        "colab_type": "text"
      },
      "source": [
        "# Model 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PSSfoS5sfWK",
        "colab_type": "text"
      },
      "source": [
        "* 지금까지 좋은 성능을 보였던 모델들을 모두 불러와 (각 모델들의 예측값들의 합)/(모델의 수) 를 계산하여 '앙상블 기법'을 적용한 결과값 도출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0HKd0rRc5mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def swish(x) :\n",
        "    return x * keras.activations.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGk24CNH9IED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 좋은 성능을 보였던 모델을 모두 불러옵니다.\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model_12_200 = load_model('/gdrive/My Drive/DACON-semiconductor-competition/model_12.h5', custom_objects={'swish':swish})\n",
        "model_12_300 = load_model('/gdrive/My Drive/DACON-semiconductor-competition/model_12_300.h5', custom_objects={'swish':swish})\n",
        "model_13_200 = load_model('/gdrive/My Drive/DACON-semiconductor-competition/model_13.h5', custom_objects={'swish':swish})\n",
        "model_13_250 = load_model('/gdrive/My Drive/DACON-semiconductor-competition/model_13_250.h5', custom_objects={'swish':swish})\n",
        "model_13_300 = load_model('/gdrive/My Drive/DACON-semiconductor-competition/model_13_300.h5', custom_objects={'swish':swish})\n",
        "model_14_200 = load_model('/gdrive/My Drive/DACON-semiconductor-competition/model_14.h5', custom_objects={'swish':swish})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg5-4WZBcuZ5",
        "colab_type": "code",
        "outputId": "6c3e4168-6ecb-4ba3-c6d9-9494ff3f3e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# 좋은 성능을 보였던 모델들의 성능을 평가합니다.\n",
        "# 모델들간의 큰 성능의 차이가 없으므로 6개의 모델을 모두 앙상블 방법으로 적용합니다.\n",
        "\n",
        "model_list = [model_12_200, model_12_300, model_13_200, model_13_250, model_13_300, model_14_200]\n",
        "\n",
        "model_evaluate = {}\n",
        "for model in model_list:\n",
        "    results = model.evaluate(train_X, train_Y, batch_size=630)\n",
        "    model_evaluate[model] = results\n",
        "    print('test loss, test acc: ', results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "810000/810000 [==============================] - 9s 12us/step\n",
            "test loss, test acc:  [1.2413994020753436, 0.967248135275311]\n",
            "810000/810000 [==============================] - 8s 9us/step\n",
            "test loss, test acc:  [1.0118190819687314, 0.971292579167419]\n",
            "810000/810000 [==============================] - 8s 10us/step\n",
            "test loss, test acc:  [1.1997492327226533, 0.9680110984974437]\n",
            "810000/810000 [==============================] - 8s 10us/step\n",
            "test loss, test acc:  [0.9881053525739246, 0.9650604800979297]\n",
            "810000/810000 [==============================] - 8s 10us/step\n",
            "test loss, test acc:  [1.2487017318142786, 0.9687123325169087]\n",
            "810000/810000 [==============================] - 9s 11us/step\n",
            "test loss, test acc:  [1.0525636264218226, 0.9689110983444584]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrB-LwLOgeM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예측값을 생성합니다.\n",
        "\n",
        "model_predict = []\n",
        "for model in model_list:\n",
        "    model_predict.append(model.predict(test_X))\n",
        "\n",
        "pred_test = sum(model_predict)/6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv6yp_Hzoq4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission 파일을 생성합니다.\n",
        "sample_sub = pd.read_csv('/gdrive/My Drive/DACON-semiconductor-competition/dataset/sample_submission.csv', index_col=0)\n",
        "submission = sample_sub+pred_test\n",
        "submission.to_csv('/gdrive/My Drive/DACON-semiconductor-competition/submission_16.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IaqhJqmV_5",
        "colab_type": "text"
      },
      "source": [
        "### Bayesian Optimization\n",
        "http://research.sualab.com/introduction/practice/2019/02/19/bayesian-optimization-overview-1.html<br>\n",
        "http://research.sualab.com/introduction/practice/2019/04/01/bayesian-optimization-overview-2.html<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNwDuaRWmWg4",
        "colab_type": "text"
      },
      "source": [
        "### Swish Activation\n",
        "https://www.machinecurve.com/index.php/2019/05/30/why-swish-could-perform-better-than-relu/#todays-activation-functions"
      ]
    }
  ]
}